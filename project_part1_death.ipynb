{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "# importing module\n",
    "from pandas import *\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "from helper760 import read_inputs\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "n_split=8           # define number for k\n",
    "re_train_1 = True  # define for the step 1 (CT+Clinic -> Death Day), do we want to retrain the model?\n",
    "re_train_2 = False  # define for the step 2 (CT -> Death Day), do we want to retrain the model?\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Use both clinic and ct data to predict death day\n",
    "Note that we have only around 549 real samples with known death day for us to train the model\n",
    "\n",
    "Currently, we use these 549 samples as training set, and the rest will be the prediction set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data for step 1\n",
    "Clininc_Data,Outcome_Data,CT_Data = read_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out who has known death day\n",
    "n_sample = len(Outcome_Data[0])\n",
    "fill_train_idx = []\n",
    "fill_test_idx = []\n",
    "\n",
    "for i in range(n_sample):\n",
    "    if Outcome_Data[0][i]!=0:\n",
    "        fill_train_idx.append(i)\n",
    "    else:\n",
    "        fill_test_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(9223, 10)\n",
      "(9223, 21)\n",
      "(549, 21)\n",
      "(8674, 21)\n",
      "(549, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare the data for training\n",
    "# in this case we use both the clinic data and ct data\n",
    "X1 = np.array(CT_Data)\n",
    "X1 = X1.T\n",
    "X1 = X1.astype(float)\n",
    "print(X1.shape)\n",
    "\n",
    "X2 = np.array(Clininc_Data)\n",
    "X2 = X2.T\n",
    "X2 = X2[:,4:14]\n",
    "X2 = X2.astype(float)\n",
    "print(X2.shape)\n",
    "\n",
    "X = np.hstack((X1,X2))\n",
    "print(X.shape)\n",
    "\n",
    "X_fill_train = X[fill_train_idx,:]\n",
    "print(X_fill_train.shape)\n",
    "\n",
    "X_fill_test = X[fill_test_idx,:]\n",
    "print(X_fill_test.shape)\n",
    "\n",
    "y_fill_train = np.array(Outcome_Data[0])\n",
    "y_fill_train = y_fill_train.astype(int)\n",
    "y_fill_train = np.asmatrix(y_fill_train)\n",
    "y_fill_train = y_fill_train.T\n",
    "y_fill_train = y_fill_train[fill_train_idx,:]\n",
    "print(y_fill_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training fold 0 total 8 folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 18:39:45.108831: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 18:39:45.229218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.229403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.229563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.229714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.229862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.230019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.724774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.725004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.725233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.725450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.725723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.725892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7383 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:23:00.0, compute capability: 6.1\n",
      "2022-05-09 18:39:45.726131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 18:39:45.726281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6927 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:2d:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb#ch0000005?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMeanSquaredError\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mopt, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mMeanSquaredError\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb#ch0000005?line=22'>23</a>\u001b[0m \u001b[39m# fit the keras model on the dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb#ch0000005?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb#ch0000005?line=24'>25</a>\u001b[0m eva \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test,y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jason/Desktop/STUDY/Coursework/760Project/project_part1_death.ipynb#ch0000005?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfold \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(counter)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m eva: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(eva[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/jason/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model use the 549 samples, with clinic data + ct data\n",
    "if re_train_1 == True:\n",
    "    models = []\n",
    "    evas = []\n",
    "    counter = 0\n",
    "    for train_index,test_index in KFold(n_split).split(X_fill_train):\n",
    "        print(\"training fold \"+str(counter)+\" total \"+str(n_split) +\" folds\")\n",
    "\n",
    "        x_train,x_test = X_fill_train[train_index], X_fill_train[test_index]\n",
    "        y_train,y_test = y_fill_train[train_index], y_fill_train[test_index]\n",
    "    \n",
    "        # define the keras model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_dim=21, use_bias=True))\n",
    "        model.add(Dense(64, activation='relu',use_bias=True))\n",
    "        model.add(Dense(128, activation='relu',use_bias=True))\n",
    "        model.add(Dense(256, activation='relu',use_bias=True))\n",
    "        model.add(Dense(512, activation='relu',use_bias=True))\n",
    "        model.add(Dense(1))\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "        # compile the keras model\n",
    "        model.compile(loss='MeanSquaredError', optimizer=opt, metrics=['MeanSquaredError'])\n",
    "        # fit the keras model on the dataset\n",
    "        model.fit(x_train, y_train, epochs=3000, batch_size=5,verbose=1)\n",
    "        eva = model.evaluate(x_test,y_test)\n",
    "        \n",
    "        print(\"fold \"+str(counter)+\" eva: \"+str(eva[0]))\n",
    "        counter = counter + 1\n",
    "        \n",
    "        models.append(model)\n",
    "        evas.append(eva)\n",
    "    for i in range(len(evas)):\n",
    "        evas[i] = evas[i][0]\n",
    "    # find the best evaluated models\n",
    "    model = models[evas.index(min(evas))]\n",
    "\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"NN_models/keras_model_step_1\", custom_objects=None, compile=True, options=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average death day error across all 549 traing sample: 420.6206548027219\n"
     ]
    }
   ],
   "source": [
    "# let's see how the model fits the original training data\n",
    "y_fill_train_predict = model.predict(X_fill_train)\n",
    "err_sum = 0\n",
    "for i in range((y_fill_train_predict.shape)[0]):\n",
    "    err_sum = err_sum + (abs(y_fill_train_predict[i,0]-y_fill_train[i,0]))\n",
    "print(\"average death day error across all 549 traing sample: \"+str(err_sum/(y_fill_train_predict.shape)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 17:51:28.585930: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_models/keras_model_step_1/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model used for step 1\n",
    "from datetime import datetime\n",
    "if re_train_1 == True:\n",
    "    model.save(\"NN_models/keras_model_step_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 25)\n",
      "(9223, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_368642/407643235.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_outcome = np.array(Outcome_Data)\n"
     ]
    }
   ],
   "source": [
    "# fill in the missing death day data using both clinic data and ct data\n",
    "y_fill_test_predict = model.predict(X_fill_test)\n",
    "for i in range(len(fill_test_idx)):\n",
    "    if y_fill_test_predict[i] < 0:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = 0\n",
    "    else:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = y_fill_test_predict[i]\n",
    "\n",
    "np_outcome = np.array(Outcome_Data)\n",
    "np_ctdata = np.array(CT_Data)\n",
    "np_outcome = np_outcome.T\n",
    "np_ctdata = np_ctdata.T\n",
    "print(np_outcome.shape)\n",
    "print(np_ctdata.shape)\n",
    "\n",
    "out_csv = np.column_stack((np_outcome,np_ctdata))\n",
    "out_csv = out_csv.astype(float)\n",
    "\n",
    "np.savetxt(\"test_death_day_1.csv\", out_csv, fmt='%f',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Use only ct data to predict death day\n",
    "Note that we have only around 549 real samples with known death day for us to train the model\n",
    "\n",
    "In this case, we use only CT data to predict death, we use the 549 samples with death day as training set, and predict the samples with missing death day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reread the data to clear variables\n",
    "Clininc_Data,Outcome_Data,CT_Data = read_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(549, 11)\n",
      "(8674, 11)\n",
      "(549, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare data for training, this case we use ct data only\n",
    "X1 = np.array(CT_Data)\n",
    "X1 = X1.T\n",
    "X1 = X1.astype(float)\n",
    "print(X1.shape)\n",
    "\n",
    "X_fill_train_2 = X1[fill_train_idx,:]\n",
    "print(X_fill_train_2.shape)\n",
    "\n",
    "X_fill_test_2 = X1[fill_test_idx,:]\n",
    "print(X_fill_test_2.shape)\n",
    "\n",
    "y_fill_train_2 = np.array(Outcome_Data[0])\n",
    "y_fill_train_2 = y_fill_train_2.astype(int)\n",
    "y_fill_train_2 = np.asmatrix(y_fill_train_2)\n",
    "y_fill_train_2 = y_fill_train_2.T\n",
    "y_fill_train_2 = y_fill_train_2[fill_train_idx,:]\n",
    "print(y_fill_train_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model used for step 2\n",
    "if re_train_2 == True:\n",
    "    models_2 = []\n",
    "    evas_2 = []\n",
    "    counter = 0\n",
    "    for train_index,test_index in KFold(n_split).split(X_fill_train_2):\n",
    "        print(\"training fold \"+str(counter)+\" total \"+str(n_split) +\" folds\")\n",
    "\n",
    "        x_train,x_test = X_fill_train_2[train_index], X_fill_train_2[test_index]\n",
    "        y_train,y_test = y_fill_train_2[train_index], y_fill_train_2[test_index]\n",
    "        # define the keras model\n",
    "        model_2 = Sequential()\n",
    "        model_2.add(Dense(32, input_dim=11, use_bias=True))\n",
    "        model_2.add(Dense(64, activation='relu',use_bias=True))\n",
    "        model_2.add(Dense(128, activation='relu',use_bias=True))\n",
    "        model_2.add(Dense(256, activation='relu',use_bias=True))\n",
    "        model_2.add(Dense(512, activation='relu',use_bias=True))\n",
    "        model_2.add(Dense(1))\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "        # compile the keras model\n",
    "        model_2.compile(loss='MeanSquaredError', optimizer=opt, metrics=['MeanSquaredError'])\n",
    "        # fit the keras model on the dataset\n",
    "        model_2.fit(x_train, y_train, epochs=5000, batch_size=10,verbose=1)\n",
    "        eva_2 = model_2.evaluate(x_test,y_test)\n",
    "\n",
    "        print(\"fold \"+str(counter)+\" eva: \"+str(eva_2[0]))\n",
    "        counter = counter + 1\n",
    "\n",
    "        models_2.append(model_2)\n",
    "        evas_2.append(eva_2)\n",
    "    for i in range(len(evas_2)):\n",
    "        evas_2[i] = evas_2[i][0]\n",
    "    # find the best evaluated models\n",
    "    model_2 = models_2[evas_2.index(min(evas_2))]\n",
    "else:\n",
    "    model_2 = tf.keras.models.load_model(\"NN_models/keras_model_step_2\", custom_objects=None, compile=True, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 602us/step - loss: 3.3247 - mean_squared_error: 3.3247\n",
      "[3.324714183807373, 3.324714183807373]\n",
      "average death day error across all 549 traing sample: 1.1271004911328926\n"
     ]
    }
   ],
   "source": [
    "# save/evaluate the model\n",
    "from datetime import datetime\n",
    "if re_train_2 == True:\n",
    "    model_2.save(\"NN_models/keras_model_step_2\")\n",
    "score_2 = model_2.evaluate(X_fill_train_2, y_fill_train_2, verbose = 1) \n",
    "print(score_2)\n",
    "\n",
    "# let's see how the model fits the original training set\n",
    "err_sum = 0\n",
    "y_fill_train_predict_2 = model_2.predict(X_fill_train_2)\n",
    "for i in range((y_fill_train_predict_2.shape)[0]):\n",
    "    err_sum = err_sum + (abs(y_fill_train_predict_2[i,0]-y_fill_train_2[i,0]))\n",
    "print(\"average death day error across all 549 traing sample: \"+str(err_sum/(y_fill_train_predict_2.shape)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 25)\n",
      "(9223, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_368642/3638360185.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_outcome = np.array(Outcome_Data)\n"
     ]
    }
   ],
   "source": [
    "# predict and fill the missing death day field\n",
    "y_fill_test_predict_2 = model_2.predict(X_fill_test_2)\n",
    "\n",
    "for i in range(len(fill_test_idx)):\n",
    "    if y_fill_test_predict_2[i] < 0:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = 0\n",
    "    else:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = y_fill_test_predict_2[i]\n",
    "\n",
    "np_outcome = np.array(Outcome_Data)\n",
    "np_ctdata = np.array(CT_Data)\n",
    "np_outcome = np_outcome.T\n",
    "np_ctdata = np_ctdata.T\n",
    "print(np_outcome.shape)\n",
    "print(np_ctdata.shape)\n",
    "\n",
    "out_csv = np.column_stack((np_outcome,np_ctdata))\n",
    "out_csv = out_csv.astype(float)\n",
    "\n",
    "np.savetxt(\"test_death_day_2.csv\", out_csv, fmt='%f',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
