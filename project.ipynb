{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "from pandas import *\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    " \n",
    "# reading CSV file\n",
    "data = read_csv(\"data_input/OppScrData.csv\",keep_default_na=False,low_memory=False)\n",
    "\n",
    "# ======================= Clinic Data =====================================\n",
    "Clinic_Data = []\n",
    "Clinic_Data.append(data['Record ID'].tolist())                                          # Col A\n",
    "Clinic_Data.append(data['Visit ID'].tolist())                                           # Col B\n",
    "Clinic_Data.append(data['PT ID'].tolist())                                              # Col C\n",
    "Clinic_Data.append(data['Clinical F/U interval  [d from CT]'].tolist())                 # Col D\n",
    "Clinic_Data.append(data['BMI'].tolist())                                                # Col E\n",
    "Clinic_Data.append(data['BMI >30'].tolist())                                            # Col F\n",
    "Clinic_Data.append(data['Sex'].tolist())                                                # Col G\n",
    "Clinic_Data.append(data['Age at CT'].tolist())                                          # Col H\n",
    "Clinic_Data.append(data['Tobacco'].tolist())                                            # Col I\n",
    "Clinic_Data.append(data['Alcohol abuse'].tolist())                                      # Col J\n",
    "Clinic_Data.append(data['FRS 10-year risk (%)'].tolist())                               # Col K\n",
    "Clinic_Data.append(data['FRAX 10y Fx Prob (Orange-w/ DXA)'].tolist())                   # Col L\n",
    "Clinic_Data.append(data['FRAX 10y Hip Fx Prob (Orange-w/ DXA)'].tolist())               # Col M\n",
    "Clinic_Data.append(data['Met Sx'].tolist())                                             # Col N\n",
    "\n",
    "# ======================= Outcome Data =====================================\n",
    "Outcome_Data = []\n",
    "Outcome_Data.append(data['DEATH [d from CT]'].tolist())                                 # Col P\n",
    "Outcome_Data.append(data['CVD DX'].tolist())                                            # Col Q\n",
    "Outcome_Data.append(data['CVD DX Date [d from CT]'].tolist())                           # Col R\n",
    "Outcome_Data.append(data['Heart failure DX'].tolist())                                  # Col S\n",
    "Outcome_Data.append(data['Heart failure DX Date [d from CT]'].tolist())                 # Col T\n",
    "Outcome_Data.append(data['MI DX'].tolist())                                             # Col U\n",
    "Outcome_Data.append(data['MI DX Date [d from CT]'].tolist())                            # Col V\n",
    "Outcome_Data.append(data['Type 2 Diabetes DX'].tolist())                                # Col W\n",
    "Outcome_Data.append(data['Type 2 Diabetes DX Date [d from CT]'].tolist())               # Col X\n",
    "Outcome_Data.append(data['Femoral neck fracture DX'].tolist())                          # Col Y\n",
    "Outcome_Data.append(data['Femoral neck fracture DX Date [d from CT]'].tolist())         # Col Z\n",
    "Outcome_Data.append(data['Unspec femoral fracture DX'].tolist())                        # Col AA\n",
    "Outcome_Data.append(data['Unspec femoral fracture DX Date [d from CT]'].tolist())       # Col AB\n",
    "Outcome_Data.append(data['Forearm fracture DX'].tolist())                               # Col AC\n",
    "Outcome_Data.append(data['Forearm fracture DX Date [d from CT]'].tolist())              # Col AD\n",
    "Outcome_Data.append(data['Humerus fracture DX'].tolist())                               # Col AE\n",
    "Outcome_Data.append(data['Humerus fracture DX Date [d from CT]'].tolist())              # Col AF\n",
    "Outcome_Data.append(data['Pathologic fracture DX'].tolist())                            # Col AG\n",
    "Outcome_Data.append(data['Pathologic fracture DX Date [d from CT]'].tolist())           # Col AH\n",
    "Outcome_Data.append(data['Alzheimers DX'].tolist())                                     # Col AI\n",
    "Outcome_Data.append(data['Alzheimers DX Date [d from CT]'].tolist())                    # Col AJ\n",
    "Outcome_Data.append(data['Primary Cancer Site'].tolist())                               # Col AK\n",
    "Outcome_Data.append(data['Primary Cancer Dx [d from CT]'].tolist())                      # Col AL\n",
    "Outcome_Data.append(data['Primary Cancer Site 2'].tolist())                             # Col AM\n",
    "Outcome_Data.append(data['Primary Cancer Site 2 Dx [d from CT]'].tolist())              # Col AN\n",
    "\n",
    "# ======================= CT Data =====================================\n",
    "CT_Data = []\n",
    "CT_Data.append(data['L1_HU_BMD'].tolist())                                              # Col AP\n",
    "CT_Data.append(data['TAT Area (cm2)'].tolist())                                         # Col AQ\n",
    "CT_Data.append(data['Total Body                Area EA (cm2)'].tolist())                # Col AR\n",
    "CT_Data.append(data['VAT Area (cm2)'].tolist())                                         # Col AS\n",
    "CT_Data.append(data['SAT Area (cm2)'].tolist())                                         # Col AT\n",
    "CT_Data.append(data['VAT/SAT     Ratio'].tolist())                                      # Col AU\n",
    "CT_Data.append(data['Muscle HU'].tolist())                                              # Col AV\n",
    "CT_Data.append(data[' Muscle Area (cm2)'].tolist())                                     # Col AW\n",
    "CT_Data.append(data['L3 SMI (cm2/m2)'].tolist())                                        # Col AX\n",
    "CT_Data.append(data['AoCa        Agatston'].tolist())                                   # Col AY\n",
    "CT_Data.append(data['Liver HU    (Median)'].tolist())                                   # Col AZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= Clinic Data =====================================\n",
    "# BMI - If BMI is unknown, we assign an average BMI value\n",
    "average_BMI = mean([float(l) for l in Clinic_Data[4] if l!=''])\n",
    "for i in range(len(Clinic_Data[4])):\n",
    "    if Clinic_Data[4][i] == '' or Clinic_Data[4][i] == ' ':\n",
    "        Clinic_Data[4][i] = average_BMI\n",
    "\n",
    "# BMI >30 - 0 for N, 1 for Y\n",
    "for i in range(len(Clinic_Data[5])):\n",
    "    if Clinic_Data[5][i] == 'N':\n",
    "        Clinic_Data[5][i] = 0\n",
    "    elif Clinic_Data[5][i] == 'Y':\n",
    "        Clinic_Data[5][i] = 1\n",
    "    else:\n",
    "        if float(Clinic_Data[4][i]) > 30:\n",
    "            Clinic_Data[5][i] = 1\n",
    "        else:\n",
    "            Clinic_Data[5][i] = 0\n",
    "\n",
    "\n",
    "# Sex - 0 for female, 1 for male\n",
    "for i in range(len(Clinic_Data[6])):\n",
    "    if Clinic_Data[6][i] == 'Female':\n",
    "        Clinic_Data[6][i] = 0\n",
    "    elif Clinic_Data[6][i] == 'Male':\n",
    "        Clinic_Data[6][i] = 1\n",
    "\n",
    "# Tobacco - -1 for 'No', 1 for 'Yes', 0 for unknown\n",
    "for i in range(len(Clinic_Data[8])):\n",
    "    if Clinic_Data[8][i] == 'Yes':\n",
    "        Clinic_Data[8][i] = 1\n",
    "    elif Clinic_Data[8][i] == 'No':\n",
    "        Clinic_Data[8][i] = -1\n",
    "    else:\n",
    "        Clinic_Data[8][i] = 0\n",
    "\n",
    "# Alcohol Abuse\n",
    "# We categorize alcohol abuse into several levels:\n",
    "# 5 - Acute alcoholic intoxicational alcoholism\n",
    "# 4 - Alcohol abuse\n",
    "# 3 - Alcohol dependence\n",
    "# 2 - Alcohol use\n",
    "# 1 - Other and unspecified\n",
    "for i in range(len(Clinic_Data[9])):\n",
    "    if Clinic_Data[9][i] == 'Acutealcoholicintoxicationinalcoholism,continuous' or Clinic_Data[9][i] == 'Acutealcoholicintoxicationinalcoholism,unspecified':\n",
    "        Clinic_Data[9][i] = 5\n",
    "    elif Clinic_Data[9][i] == 'Alcoholabuse,uncomplicated' or Clinic_Data[9][i] == 'Alcoholabuse,inremission' or Clinic_Data[9][i] == 'Alcoholabusewithintoxication,unspecified' or Clinic_Data[9][i] == 'Alcoholabusewithotheralcohol-induceddisorder':\n",
    "        Clinic_Data[9][i] = 4\n",
    "    elif Clinic_Data[9][i] == 'Alcoholdependence,uncomplicated' or Clinic_Data[9][i] == 'Alcoholdependence,inremission' or Clinic_Data[9][i] == 'Alcoholdependencewithwithdrawal,unspecified' or Clinic_Data[9][i] == 'Alcoholdependencewithintoxication,unspecified' or Clinic_Data[9][i]=='Alcoholdependencewithwithdrawaldelirium':\n",
    "        Clinic_Data[9][i] = 3\n",
    "    elif Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithintoxication,uncomplicated' or Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithunspecifiedalcohol-induceddisorder' or Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithalcohol-inducedsleepdisorder':\n",
    "        Clinic_Data[9][i] = 2\n",
    "    elif Clinic_Data[9][i] == 'Otherandunspecifiedalcoholdependence,unspecifieddrinkingbehavior' or Clinic_Data[9][i] == 'Otherandunspecifiedalcoholdependence,continuousdrinkingbehavior' or Clinic_Data[9][i]=='Otherandunspecifiedalcoholdependence,inremission' or Clinic_Data[9][i]=='Otherandunspecifiedalcoholdependence,episodicdrinkingbehavior':\n",
    "        Clinic_Data[9][i] = 1\n",
    "    elif Clinic_Data[9][i] == '' or Clinic_Data[9][i] == ' ':\n",
    "        Clinic_Data[9][i] = 0\n",
    "\n",
    "# FRS 10-year Risk\n",
    "# TODO\n",
    "# we consider <1 to be 0.005, >30 to be 0.4, if unknown then we give 0\n",
    "for i in range(len(Clinic_Data[10])):\n",
    "    if Clinic_Data[10][i] == '<1%':\n",
    "        Clinic_Data[10][i] = 0.005\n",
    "    elif Clinic_Data[10][i] == '>30%':\n",
    "        Clinic_Data[10][i] = 0.4\n",
    "    elif Clinic_Data[10][i] == 'X':\n",
    "        Clinic_Data[10][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[10][i] = float(Clinic_Data[10][i].strip('%'))/100\n",
    "\n",
    "# FRAX 10y Fx Prob (Orange-w/ DXA)\n",
    "# FRAX 10y Hip Fx Prob (Orange-w/ DXA)\n",
    "# convert '_' to 0 for both columns\n",
    "for i in range(len(Clinic_Data[11])):\n",
    "    if Clinic_Data[11][i] == '_':\n",
    "        Clinic_Data[11][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[11][i] = float(Clinic_Data[11][i])\n",
    "    \n",
    "for i in range(len(Clinic_Data[12])):\n",
    "    if Clinic_Data[12][i] == '_':\n",
    "        Clinic_Data[12][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[12][i] = float(Clinic_Data[12][i])\n",
    "\n",
    "# Met Sx\n",
    "# set -1 if 'N', set 1 if 'Y', set 0 if unknown\n",
    "for i in range(len(Clinic_Data[13])):\n",
    "    if Clinic_Data[13][i] == '' or Clinic_Data[13][i] == ' ':\n",
    "        Clinic_Data[13][i] = 0\n",
    "    elif Clinic_Data[13][i] == 'N':\n",
    "        Clinic_Data[13][i] = -1\n",
    "    elif Clinic_Data[13][i] == 'Y':\n",
    "        Clinic_Data[13][i] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average(list):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for i in range(len(list)):\n",
    "        if list[i]!='' and list[i]!=' ':\n",
    "            sum = sum + float(list[i])\n",
    "            count = count + 1\n",
    "    \n",
    "    if count!= 0:\n",
    "        return sum/count\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= CT Data =====================================\n",
    "# fill in unknowns with mean value of all known fields\n",
    "for i in range(len(CT_Data)):\n",
    "    average = compute_average(CT_Data[i])\n",
    "    for j in range(len(CT_Data[i])):\n",
    "        if CT_Data[i][j] == '' or CT_Data[i][j] == ' ':\n",
    "            CT_Data[i][j] = average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= Clinical Data =====================================\n",
    "for i in range(len(Outcome_Data)):\n",
    "    for j in range(len(Outcome_Data[i])):\n",
    "        if Outcome_Data[i][j] == '' or Outcome_Data[i][j] == ' ':\n",
    "            Outcome_Data[i][j] = 0\n",
    "        else:\n",
    "            Outcome_Data[i][j] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "185/185 [==============================] - 1s 775us/step - loss: 1.9296 - accuracy: 0.7936 - precision: 0.1501 - recall: 0.1232\n",
      "Epoch 2/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.9610 - accuracy: 0.8109 - precision: 0.1685 - recall: 0.1125\n",
      "Epoch 3/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.8320 - accuracy: 0.8197 - precision: 0.1408 - recall: 0.0736\n",
      "Epoch 4/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.8526 - accuracy: 0.8219 - precision: 0.1641 - recall: 0.0877\n",
      "Epoch 5/250\n",
      "185/185 [==============================] - 0s 817us/step - loss: 0.8083 - accuracy: 0.8272 - precision: 0.1629 - recall: 0.0769\n",
      "Epoch 6/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.7793 - accuracy: 0.8268 - precision: 0.1560 - recall: 0.0728\n",
      "Epoch 7/250\n",
      "185/185 [==============================] - 0s 818us/step - loss: 0.6462 - accuracy: 0.8380 - precision: 0.1798 - recall: 0.0662\n",
      "Epoch 8/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.8204 - accuracy: 0.8254 - precision: 0.1607 - recall: 0.0786\n",
      "Epoch 9/250\n",
      "185/185 [==============================] - 0s 823us/step - loss: 0.8647 - accuracy: 0.8324 - precision: 0.1897 - recall: 0.0852\n",
      "Epoch 10/250\n",
      "185/185 [==============================] - 0s 821us/step - loss: 0.9770 - accuracy: 0.8274 - precision: 0.1814 - recall: 0.0902\n",
      "Epoch 11/250\n",
      "185/185 [==============================] - 0s 812us/step - loss: 0.7315 - accuracy: 0.8349 - precision: 0.1729 - recall: 0.0687\n",
      "Epoch 12/250\n",
      "185/185 [==============================] - 0s 896us/step - loss: 0.6858 - accuracy: 0.8368 - precision: 0.1942 - recall: 0.0778\n",
      "Epoch 13/250\n",
      "185/185 [==============================] - 0s 853us/step - loss: 0.6613 - accuracy: 0.8417 - precision: 0.2102 - recall: 0.0753\n",
      "Epoch 14/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.7390 - accuracy: 0.8391 - precision: 0.1965 - recall: 0.0736\n",
      "Epoch 15/250\n",
      "185/185 [==============================] - 0s 937us/step - loss: 0.7387 - accuracy: 0.8290 - precision: 0.1642 - recall: 0.0744\n",
      "Epoch 16/250\n",
      "185/185 [==============================] - 0s 899us/step - loss: 0.6232 - accuracy: 0.8447 - precision: 0.1995 - recall: 0.0612\n",
      "Epoch 17/250\n",
      "185/185 [==============================] - 0s 932us/step - loss: 0.7380 - accuracy: 0.8332 - precision: 0.1493 - recall: 0.0579\n",
      "Epoch 18/250\n",
      "185/185 [==============================] - 0s 820us/step - loss: 0.7228 - accuracy: 0.8376 - precision: 0.1971 - recall: 0.0778\n",
      "Epoch 19/250\n",
      "185/185 [==============================] - 0s 902us/step - loss: 0.7199 - accuracy: 0.8327 - precision: 0.1813 - recall: 0.0786\n",
      "Epoch 20/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.6717 - accuracy: 0.8471 - precision: 0.2443 - recall: 0.0794\n",
      "Epoch 21/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.6485 - accuracy: 0.8426 - precision: 0.2000 - recall: 0.0670\n",
      "Epoch 22/250\n",
      "185/185 [==============================] - 0s 816us/step - loss: 0.5266 - accuracy: 0.8510 - precision: 0.2581 - recall: 0.0728\n",
      "Epoch 23/250\n",
      "185/185 [==============================] - 0s 809us/step - loss: 0.5607 - accuracy: 0.8474 - precision: 0.2071 - recall: 0.0579\n",
      "Epoch 24/250\n",
      "185/185 [==============================] - 0s 795us/step - loss: 0.6653 - accuracy: 0.8402 - precision: 0.2088 - recall: 0.0786\n",
      "Epoch 25/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.7400 - accuracy: 0.8363 - precision: 0.2197 - recall: 0.0976\n",
      "Epoch 26/250\n",
      "185/185 [==============================] - 0s 872us/step - loss: 0.7072 - accuracy: 0.8403 - precision: 0.2000 - recall: 0.0728\n",
      "Epoch 27/250\n",
      "185/185 [==============================] - 0s 869us/step - loss: 0.5421 - accuracy: 0.8502 - precision: 0.2288 - recall: 0.0604\n",
      "Epoch 28/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.5540 - accuracy: 0.8498 - precision: 0.2301 - recall: 0.0620\n",
      "Epoch 29/250\n",
      "185/185 [==============================] - 0s 854us/step - loss: 0.5575 - accuracy: 0.8496 - precision: 0.2236 - recall: 0.0596\n",
      "Epoch 30/250\n",
      "185/185 [==============================] - 0s 903us/step - loss: 0.6487 - accuracy: 0.8481 - precision: 0.2193 - recall: 0.0620\n",
      "Epoch 31/250\n",
      "185/185 [==============================] - 0s 941us/step - loss: 0.8999 - accuracy: 0.8344 - precision: 0.1942 - recall: 0.0835\n",
      "Epoch 32/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.6352 - accuracy: 0.8466 - precision: 0.2155 - recall: 0.0645\n",
      "Epoch 33/250\n",
      "185/185 [==============================] - 0s 827us/step - loss: 0.5649 - accuracy: 0.8489 - precision: 0.2239 - recall: 0.0620\n",
      "Epoch 34/250\n",
      "185/185 [==============================] - 0s 871us/step - loss: 0.5933 - accuracy: 0.8497 - precision: 0.2374 - recall: 0.0662\n",
      "Epoch 35/250\n",
      "185/185 [==============================] - 0s 900us/step - loss: 0.7218 - accuracy: 0.8397 - precision: 0.2192 - recall: 0.0868\n",
      "Epoch 36/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.5430 - accuracy: 0.8516 - precision: 0.2368 - recall: 0.0596\n",
      "Epoch 37/250\n",
      "185/185 [==============================] - 0s 820us/step - loss: 0.4984 - accuracy: 0.8534 - precision: 0.2509 - recall: 0.0596\n",
      "Epoch 38/250\n",
      "185/185 [==============================] - 0s 860us/step - loss: 0.5663 - accuracy: 0.8482 - precision: 0.2310 - recall: 0.0678\n",
      "Epoch 39/250\n",
      "185/185 [==============================] - 0s 779us/step - loss: 0.6376 - accuracy: 0.8446 - precision: 0.2321 - recall: 0.0802\n",
      "Epoch 40/250\n",
      "185/185 [==============================] - 0s 810us/step - loss: 0.6796 - accuracy: 0.8392 - precision: 0.2260 - recall: 0.0935\n",
      "Epoch 41/250\n",
      "185/185 [==============================] - 0s 795us/step - loss: 0.5463 - accuracy: 0.8527 - precision: 0.2517 - recall: 0.0629\n",
      "Epoch 42/250\n",
      "185/185 [==============================] - 0s 800us/step - loss: 0.5460 - accuracy: 0.8497 - precision: 0.2294 - recall: 0.0620\n",
      "Epoch 43/250\n",
      "185/185 [==============================] - 0s 788us/step - loss: 0.4818 - accuracy: 0.8557 - precision: 0.2617 - recall: 0.0554\n",
      "Epoch 44/250\n",
      "185/185 [==============================] - 0s 812us/step - loss: 0.5648 - accuracy: 0.8512 - precision: 0.2274 - recall: 0.0562\n",
      "Epoch 45/250\n",
      "185/185 [==============================] - 0s 881us/step - loss: 0.6100 - accuracy: 0.8466 - precision: 0.2261 - recall: 0.0703\n",
      "Epoch 46/250\n",
      "185/185 [==============================] - 0s 876us/step - loss: 0.4685 - accuracy: 0.8547 - precision: 0.2165 - recall: 0.0414\n",
      "Epoch 47/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.5039 - accuracy: 0.8570 - precision: 0.3022 - recall: 0.0695\n",
      "Epoch 48/250\n",
      "185/185 [==============================] - 0s 907us/step - loss: 0.5453 - accuracy: 0.8520 - precision: 0.2578 - recall: 0.0687\n",
      "Epoch 49/250\n",
      "185/185 [==============================] - 0s 924us/step - loss: 0.4804 - accuracy: 0.8579 - precision: 0.3111 - recall: 0.0695\n",
      "Epoch 50/250\n",
      "185/185 [==============================] - 0s 827us/step - loss: 0.4846 - accuracy: 0.8553 - precision: 0.2750 - recall: 0.0637\n",
      "Epoch 51/250\n",
      "185/185 [==============================] - 0s 829us/step - loss: 0.4680 - accuracy: 0.8576 - precision: 0.2886 - recall: 0.0587\n",
      "Epoch 52/250\n",
      "185/185 [==============================] - 0s 855us/step - loss: 0.4796 - accuracy: 0.8558 - precision: 0.2700 - recall: 0.0587\n",
      "Epoch 53/250\n",
      "185/185 [==============================] - 0s 782us/step - loss: 0.5489 - accuracy: 0.8536 - precision: 0.2658 - recall: 0.0662\n",
      "Epoch 54/250\n",
      "185/185 [==============================] - 0s 813us/step - loss: 0.4573 - accuracy: 0.8563 - precision: 0.2769 - recall: 0.0596\n",
      "Epoch 55/250\n",
      "185/185 [==============================] - 0s 797us/step - loss: 0.6223 - accuracy: 0.8414 - precision: 0.1727 - recall: 0.0554\n",
      "Epoch 56/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.4795 - accuracy: 0.8555 - precision: 0.2559 - recall: 0.0538\n",
      "Epoch 57/250\n",
      "185/185 [==============================] - 0s 870us/step - loss: 0.4811 - accuracy: 0.8568 - precision: 0.2846 - recall: 0.0612\n",
      "Epoch 58/250\n",
      "185/185 [==============================] - 0s 863us/step - loss: 0.5506 - accuracy: 0.8467 - precision: 0.2096 - recall: 0.0612\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 904us/step - loss: 0.5803 - accuracy: 0.8467 - precision: 0.2351 - recall: 0.0753\n",
      "Epoch 60/250\n",
      "185/185 [==============================] - 0s 943us/step - loss: 0.4527 - accuracy: 0.8581 - precision: 0.2727 - recall: 0.0496\n",
      "Epoch 61/250\n",
      "185/185 [==============================] - 0s 901us/step - loss: 0.6118 - accuracy: 0.8452 - precision: 0.2033 - recall: 0.0620\n",
      "Epoch 62/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.4811 - accuracy: 0.8547 - precision: 0.2686 - recall: 0.0629\n",
      "Epoch 63/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.5161 - accuracy: 0.8574 - precision: 0.2946 - recall: 0.0629\n",
      "Epoch 64/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.4715 - accuracy: 0.8550 - precision: 0.2419 - recall: 0.0496\n",
      "Epoch 65/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.5352 - accuracy: 0.8523 - precision: 0.2632 - recall: 0.0703\n",
      "Epoch 66/250\n",
      "185/185 [==============================] - 0s 814us/step - loss: 0.4703 - accuracy: 0.8575 - precision: 0.2925 - recall: 0.0612\n",
      "Epoch 67/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.4989 - accuracy: 0.8541 - precision: 0.2434 - recall: 0.0538\n",
      "Epoch 68/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.4518 - accuracy: 0.8588 - precision: 0.2969 - recall: 0.0562\n",
      "Epoch 69/250\n",
      "185/185 [==============================] - 0s 890us/step - loss: 0.4412 - accuracy: 0.8600 - precision: 0.2929 - recall: 0.0480\n",
      "Epoch 70/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.4900 - accuracy: 0.8555 - precision: 0.2578 - recall: 0.0546\n",
      "Epoch 71/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.4357 - accuracy: 0.8622 - precision: 0.3551 - recall: 0.0629\n",
      "Epoch 72/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.4603 - accuracy: 0.8567 - precision: 0.2731 - recall: 0.0562\n",
      "Epoch 73/250\n",
      "185/185 [==============================] - 0s 824us/step - loss: 0.4741 - accuracy: 0.8556 - precision: 0.2679 - recall: 0.0587\n",
      "Epoch 74/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.4871 - accuracy: 0.8562 - precision: 0.2903 - recall: 0.0670\n",
      "Epoch 75/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.4898 - accuracy: 0.8609 - precision: 0.3221 - recall: 0.0554\n",
      "Epoch 76/250\n",
      "185/185 [==============================] - 0s 868us/step - loss: 0.4202 - accuracy: 0.8613 - precision: 0.3011 - recall: 0.0438\n",
      "Epoch 77/250\n",
      "185/185 [==============================] - 0s 868us/step - loss: 0.4783 - accuracy: 0.8548 - precision: 0.2421 - recall: 0.0505\n",
      "Epoch 78/250\n",
      "185/185 [==============================] - 0s 909us/step - loss: 0.4815 - accuracy: 0.8553 - precision: 0.2460 - recall: 0.0505\n",
      "Epoch 79/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.4795 - accuracy: 0.8560 - precision: 0.2648 - recall: 0.0554\n",
      "Epoch 80/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.4401 - accuracy: 0.8601 - precision: 0.2659 - recall: 0.0380\n",
      "Epoch 81/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.4474 - accuracy: 0.8586 - precision: 0.2831 - recall: 0.0513\n",
      "Epoch 82/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.4361 - accuracy: 0.8606 - precision: 0.2873 - recall: 0.0430\n",
      "Epoch 83/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.4220 - accuracy: 0.8584 - precision: 0.2587 - recall: 0.0430\n",
      "Epoch 84/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.4365 - accuracy: 0.8608 - precision: 0.2995 - recall: 0.0463\n",
      "Epoch 85/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.4276 - accuracy: 0.8589 - precision: 0.2653 - recall: 0.0430\n",
      "Epoch 86/250\n",
      "185/185 [==============================] - 0s 922us/step - loss: 0.4173 - accuracy: 0.8615 - precision: 0.3068 - recall: 0.0447\n",
      "Epoch 87/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.4188 - accuracy: 0.8600 - precision: 0.2970 - recall: 0.0496\n",
      "Epoch 88/250\n",
      "185/185 [==============================] - 0s 851us/step - loss: 0.4399 - accuracy: 0.8594 - precision: 0.3151 - recall: 0.0620\n",
      "Epoch 89/250\n",
      "185/185 [==============================] - 0s 839us/step - loss: 0.4250 - accuracy: 0.8619 - precision: 0.3099 - recall: 0.0438\n",
      "Epoch 90/250\n",
      "185/185 [==============================] - 0s 866us/step - loss: 0.4063 - accuracy: 0.8621 - precision: 0.3333 - recall: 0.0521\n",
      "Epoch 91/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.4361 - accuracy: 0.8595 - precision: 0.2814 - recall: 0.0463\n",
      "Epoch 92/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.4117 - accuracy: 0.8620 - precision: 0.3161 - recall: 0.0455\n",
      "Epoch 93/250\n",
      "185/185 [==============================] - 0s 791us/step - loss: 0.4361 - accuracy: 0.8588 - precision: 0.3021 - recall: 0.0587\n",
      "Epoch 94/250\n",
      "185/185 [==============================] - 0s 820us/step - loss: 0.3931 - accuracy: 0.8657 - precision: 0.3881 - recall: 0.0430\n",
      "Epoch 95/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.4233 - accuracy: 0.8590 - precision: 0.2667 - recall: 0.0430\n",
      "Epoch 96/250\n",
      "185/185 [==============================] - 0s 903us/step - loss: 0.4528 - accuracy: 0.8595 - precision: 0.2977 - recall: 0.0529\n",
      "Epoch 97/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3951 - accuracy: 0.8628 - precision: 0.3158 - recall: 0.0397\n",
      "Epoch 98/250\n",
      "185/185 [==============================] - 0s 913us/step - loss: 0.4070 - accuracy: 0.8647 - precision: 0.3725 - recall: 0.0471\n",
      "Epoch 99/250\n",
      "185/185 [==============================] - 0s 929us/step - loss: 0.4047 - accuracy: 0.8638 - precision: 0.3464 - recall: 0.0438\n",
      "Epoch 100/250\n",
      "185/185 [==============================] - 0s 923us/step - loss: 0.4492 - accuracy: 0.8612 - precision: 0.3394 - recall: 0.0620\n",
      "Epoch 101/250\n",
      "185/185 [==============================] - 0s 894us/step - loss: 0.4194 - accuracy: 0.8609 - precision: 0.3112 - recall: 0.0505\n",
      "Epoch 102/250\n",
      "185/185 [==============================] - 0s 818us/step - loss: 0.4063 - accuracy: 0.8618 - precision: 0.3103 - recall: 0.0447\n",
      "Epoch 103/250\n",
      "185/185 [==============================] - 0s 804us/step - loss: 0.4260 - accuracy: 0.8592 - precision: 0.2897 - recall: 0.0513\n",
      "Epoch 104/250\n",
      "185/185 [==============================] - 0s 793us/step - loss: 0.3942 - accuracy: 0.8651 - precision: 0.3684 - recall: 0.0405\n",
      "Epoch 105/250\n",
      "185/185 [==============================] - 0s 862us/step - loss: 0.4094 - accuracy: 0.8630 - precision: 0.3179 - recall: 0.0397\n",
      "Epoch 106/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.3803 - accuracy: 0.8660 - precision: 0.3902 - recall: 0.0397\n",
      "Epoch 107/250\n",
      "185/185 [==============================] - 0s 858us/step - loss: 0.4052 - accuracy: 0.8632 - precision: 0.3468 - recall: 0.0496\n",
      "Epoch 108/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.3938 - accuracy: 0.8648 - precision: 0.3782 - recall: 0.0488\n",
      "Epoch 109/250\n",
      "185/185 [==============================] - 0s 891us/step - loss: 0.4036 - accuracy: 0.8660 - precision: 0.4118 - recall: 0.0521\n",
      "Epoch 110/250\n",
      "185/185 [==============================] - 0s 932us/step - loss: 0.3816 - accuracy: 0.8667 - precision: 0.4219 - recall: 0.0447\n",
      "Epoch 111/250\n",
      "185/185 [==============================] - 0s 924us/step - loss: 0.4092 - accuracy: 0.8653 - precision: 0.3922 - recall: 0.0496\n",
      "Epoch 112/250\n",
      "185/185 [==============================] - 0s 912us/step - loss: 0.3943 - accuracy: 0.8648 - precision: 0.3643 - recall: 0.0422\n",
      "Epoch 113/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.3774 - accuracy: 0.8678 - precision: 0.4569 - recall: 0.0438\n",
      "Epoch 114/250\n",
      "185/185 [==============================] - 0s 881us/step - loss: 0.4102 - accuracy: 0.8617 - precision: 0.3107 - recall: 0.0455\n",
      "Epoch 115/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.4151 - accuracy: 0.8628 - precision: 0.3542 - recall: 0.0562\n",
      "Epoch 116/250\n",
      "185/185 [==============================] - 0s 869us/step - loss: 0.3723 - accuracy: 0.8667 - precision: 0.4153 - recall: 0.0405\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 906us/step - loss: 0.3887 - accuracy: 0.8658 - precision: 0.4014 - recall: 0.0488\n",
      "Epoch 118/250\n",
      "185/185 [==============================] - 0s 864us/step - loss: 0.3952 - accuracy: 0.8646 - precision: 0.3780 - recall: 0.0513\n",
      "Epoch 119/250\n",
      "185/185 [==============================] - 0s 818us/step - loss: 0.4091 - accuracy: 0.8600 - precision: 0.2908 - recall: 0.0471\n",
      "Epoch 120/250\n",
      "185/185 [==============================] - 0s 851us/step - loss: 0.3806 - accuracy: 0.8657 - precision: 0.3929 - recall: 0.0455\n",
      "Epoch 121/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.3942 - accuracy: 0.8641 - precision: 0.3514 - recall: 0.0430\n",
      "Epoch 122/250\n",
      "185/185 [==============================] - 0s 809us/step - loss: 0.3787 - accuracy: 0.8671 - precision: 0.4380 - recall: 0.0496\n",
      "Epoch 123/250\n",
      "185/185 [==============================] - 0s 799us/step - loss: 0.3808 - accuracy: 0.8662 - precision: 0.4214 - recall: 0.0554\n",
      "Epoch 124/250\n",
      "185/185 [==============================] - 0s 864us/step - loss: 0.3834 - accuracy: 0.8672 - precision: 0.4394 - recall: 0.0480\n",
      "Epoch 125/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.3779 - accuracy: 0.8674 - precision: 0.4514 - recall: 0.0538\n",
      "Epoch 126/250\n",
      "185/185 [==============================] - 0s 879us/step - loss: 0.3824 - accuracy: 0.8645 - precision: 0.3525 - recall: 0.0405\n",
      "Epoch 127/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3729 - accuracy: 0.8672 - precision: 0.4333 - recall: 0.0430\n",
      "Epoch 128/250\n",
      "185/185 [==============================] - 0s 835us/step - loss: 0.3863 - accuracy: 0.8661 - precision: 0.4167 - recall: 0.0538\n",
      "Epoch 129/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.3743 - accuracy: 0.8684 - precision: 0.4815 - recall: 0.0538\n",
      "Epoch 130/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.3745 - accuracy: 0.8664 - precision: 0.4148 - recall: 0.0463\n",
      "Epoch 131/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.3975 - accuracy: 0.8640 - precision: 0.3653 - recall: 0.0505\n",
      "Epoch 132/250\n",
      "185/185 [==============================] - 0s 804us/step - loss: 0.3715 - accuracy: 0.8683 - precision: 0.4762 - recall: 0.0496\n",
      "Epoch 133/250\n",
      "185/185 [==============================] - 0s 858us/step - loss: 0.3733 - accuracy: 0.8651 - precision: 0.3899 - recall: 0.0513\n",
      "Epoch 134/250\n",
      "185/185 [==============================] - 0s 881us/step - loss: 0.3876 - accuracy: 0.8674 - precision: 0.4352 - recall: 0.0389\n",
      "Epoch 135/250\n",
      "185/185 [==============================] - 0s 809us/step - loss: 0.3716 - accuracy: 0.8685 - precision: 0.4815 - recall: 0.0430\n",
      "Epoch 136/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3844 - accuracy: 0.8672 - precision: 0.4420 - recall: 0.0505\n",
      "Epoch 137/250\n",
      "185/185 [==============================] - 0s 904us/step - loss: 0.3761 - accuracy: 0.8680 - precision: 0.4649 - recall: 0.0438\n",
      "Epoch 138/250\n",
      "185/185 [==============================] - 0s 946us/step - loss: 0.3692 - accuracy: 0.8677 - precision: 0.4560 - recall: 0.0471\n",
      "Epoch 139/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.3806 - accuracy: 0.8662 - precision: 0.4161 - recall: 0.0513\n",
      "Epoch 140/250\n",
      "185/185 [==============================] - 0s 891us/step - loss: 0.3702 - accuracy: 0.8676 - precision: 0.4552 - recall: 0.0505\n",
      "Epoch 141/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.3641 - accuracy: 0.8688 - precision: 0.4954 - recall: 0.0447\n",
      "Epoch 142/250\n",
      "185/185 [==============================] - 0s 900us/step - loss: 0.3704 - accuracy: 0.8692 - precision: 0.5128 - recall: 0.0496\n",
      "Epoch 143/250\n",
      "185/185 [==============================] - 0s 850us/step - loss: 0.3735 - accuracy: 0.8660 - precision: 0.3937 - recall: 0.0414\n",
      "Epoch 144/250\n",
      "185/185 [==============================] - 0s 923us/step - loss: 0.3676 - accuracy: 0.8653 - precision: 0.3893 - recall: 0.0480\n",
      "Epoch 145/250\n",
      "185/185 [==============================] - 0s 858us/step - loss: 0.3669 - accuracy: 0.8677 - precision: 0.4586 - recall: 0.0505\n",
      "Epoch 146/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3733 - accuracy: 0.8674 - precision: 0.4507 - recall: 0.0529\n",
      "Epoch 147/250\n",
      "185/185 [==============================] - 0s 824us/step - loss: 0.3596 - accuracy: 0.8683 - precision: 0.4717 - recall: 0.0414\n",
      "Epoch 148/250\n",
      "185/185 [==============================] - 0s 888us/step - loss: 0.3667 - accuracy: 0.8665 - precision: 0.4247 - recall: 0.0513\n",
      "Epoch 149/250\n",
      "185/185 [==============================] - 0s 827us/step - loss: 0.3712 - accuracy: 0.8685 - precision: 0.4867 - recall: 0.0604\n",
      "Epoch 150/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.3621 - accuracy: 0.8678 - precision: 0.4569 - recall: 0.0438\n",
      "Epoch 151/250\n",
      "185/185 [==============================] - 0s 890us/step - loss: 0.3630 - accuracy: 0.8692 - precision: 0.5140 - recall: 0.0455\n",
      "Epoch 152/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.3632 - accuracy: 0.8708 - precision: 0.5691 - recall: 0.0579\n",
      "Epoch 153/250\n",
      "185/185 [==============================] - 0s 881us/step - loss: 0.3585 - accuracy: 0.8704 - precision: 0.5547 - recall: 0.0587\n",
      "Epoch 154/250\n",
      "185/185 [==============================] - 0s 861us/step - loss: 0.3599 - accuracy: 0.8699 - precision: 0.5360 - recall: 0.0554\n",
      "Epoch 155/250\n",
      "185/185 [==============================] - 0s 873us/step - loss: 0.3589 - accuracy: 0.8695 - precision: 0.5182 - recall: 0.0587\n",
      "Epoch 156/250\n",
      "185/185 [==============================] - 0s 887us/step - loss: 0.3527 - accuracy: 0.8706 - precision: 0.5816 - recall: 0.0471\n",
      "Epoch 157/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3544 - accuracy: 0.8713 - precision: 0.5948 - recall: 0.0571\n",
      "Epoch 158/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3609 - accuracy: 0.8705 - precision: 0.5620 - recall: 0.0562\n",
      "Epoch 159/250\n",
      "185/185 [==============================] - 0s 887us/step - loss: 0.3597 - accuracy: 0.8701 - precision: 0.5414 - recall: 0.0596\n",
      "Epoch 160/250\n",
      "185/185 [==============================] - 0s 905us/step - loss: 0.3517 - accuracy: 0.8711 - precision: 0.5806 - recall: 0.0596\n",
      "Epoch 161/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.3535 - accuracy: 0.8712 - precision: 0.5946 - recall: 0.0546\n",
      "Epoch 162/250\n",
      "185/185 [==============================] - 0s 863us/step - loss: 0.3538 - accuracy: 0.8700 - precision: 0.5391 - recall: 0.0571\n",
      "Epoch 163/250\n",
      "185/185 [==============================] - 0s 888us/step - loss: 0.3606 - accuracy: 0.8713 - precision: 0.5833 - recall: 0.0637\n",
      "Epoch 164/250\n",
      "185/185 [==============================] - 0s 902us/step - loss: 0.3525 - accuracy: 0.8705 - precision: 0.5556 - recall: 0.0620\n",
      "Epoch 165/250\n",
      "185/185 [==============================] - 0s 896us/step - loss: 0.3517 - accuracy: 0.8704 - precision: 0.5522 - recall: 0.0612\n",
      "Epoch 166/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.3513 - accuracy: 0.8709 - precision: 0.5776 - recall: 0.0554\n",
      "Epoch 167/250\n",
      "185/185 [==============================] - 0s 879us/step - loss: 0.3568 - accuracy: 0.8724 - precision: 0.6356 - recall: 0.0620\n",
      "Epoch 168/250\n",
      "185/185 [==============================] - 0s 877us/step - loss: 0.3558 - accuracy: 0.8706 - precision: 0.5580 - recall: 0.0637\n",
      "Epoch 169/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3543 - accuracy: 0.8704 - precision: 0.5515 - recall: 0.0620\n",
      "Epoch 170/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3486 - accuracy: 0.8721 - precision: 0.6179 - recall: 0.0629\n",
      "Epoch 171/250\n",
      "185/185 [==============================] - 0s 855us/step - loss: 0.3505 - accuracy: 0.8711 - precision: 0.5909 - recall: 0.0538\n",
      "Epoch 172/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.3551 - accuracy: 0.8709 - precision: 0.5643 - recall: 0.0653\n",
      "Epoch 173/250\n",
      "185/185 [==============================] - 0s 855us/step - loss: 0.3523 - accuracy: 0.8733 - precision: 0.6639 - recall: 0.0670\n",
      "Epoch 174/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 810us/step - loss: 0.3456 - accuracy: 0.8735 - precision: 0.6909 - recall: 0.0629\n",
      "Epoch 175/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.3516 - accuracy: 0.8729 - precision: 0.6178 - recall: 0.0802\n",
      "Epoch 176/250\n",
      "185/185 [==============================] - 0s 850us/step - loss: 0.3481 - accuracy: 0.8724 - precision: 0.6159 - recall: 0.0703\n",
      "Epoch 177/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.3430 - accuracy: 0.8748 - precision: 0.7547 - recall: 0.0662\n",
      "Epoch 178/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.3527 - accuracy: 0.8731 - precision: 0.6327 - recall: 0.0769\n",
      "Epoch 179/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3461 - accuracy: 0.8738 - precision: 0.6415 - recall: 0.0844\n",
      "Epoch 180/250\n",
      "185/185 [==============================] - 0s 843us/step - loss: 0.3446 - accuracy: 0.8739 - precision: 0.6769 - recall: 0.0728\n",
      "Epoch 181/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3433 - accuracy: 0.8748 - precision: 0.7288 - recall: 0.0711\n",
      "Epoch 182/250\n",
      "185/185 [==============================] - 0s 812us/step - loss: 0.3443 - accuracy: 0.8720 - precision: 0.5946 - recall: 0.0728\n",
      "Epoch 183/250\n",
      "185/185 [==============================] - 0s 893us/step - loss: 0.3379 - accuracy: 0.8759 - precision: 0.7581 - recall: 0.0778\n",
      "Epoch 184/250\n",
      "185/185 [==============================] - 0s 925us/step - loss: 0.3435 - accuracy: 0.8738 - precision: 0.6692 - recall: 0.0736\n",
      "Epoch 185/250\n",
      "185/185 [==============================] - 0s 896us/step - loss: 0.3356 - accuracy: 0.8743 - precision: 0.7049 - recall: 0.0711\n",
      "Epoch 186/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.3415 - accuracy: 0.8742 - precision: 0.6815 - recall: 0.0761\n",
      "Epoch 187/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.3452 - accuracy: 0.8752 - precision: 0.6835 - recall: 0.0893\n",
      "Epoch 188/250\n",
      "185/185 [==============================] - 0s 900us/step - loss: 0.3465 - accuracy: 0.8734 - precision: 0.6614 - recall: 0.0695\n",
      "Epoch 189/250\n",
      "185/185 [==============================] - 0s 805us/step - loss: 0.3361 - accuracy: 0.8750 - precision: 0.6972 - recall: 0.0819\n",
      "Epoch 190/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3448 - accuracy: 0.8749 - precision: 0.7007 - recall: 0.0794\n",
      "Epoch 191/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.3350 - accuracy: 0.8741 - precision: 0.6739 - recall: 0.0769\n",
      "Epoch 192/250\n",
      "185/185 [==============================] - 0s 841us/step - loss: 0.3384 - accuracy: 0.8744 - precision: 0.6835 - recall: 0.0786\n",
      "Epoch 193/250\n",
      "185/185 [==============================] - 0s 864us/step - loss: 0.3359 - accuracy: 0.8740 - precision: 0.6577 - recall: 0.0811\n",
      "Epoch 194/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.3356 - accuracy: 0.8757 - precision: 0.7032 - recall: 0.0902\n",
      "Epoch 195/250\n",
      "185/185 [==============================] - 0s 853us/step - loss: 0.3373 - accuracy: 0.8768 - precision: 0.7186 - recall: 0.0993\n",
      "Epoch 196/250\n",
      "185/185 [==============================] - 0s 838us/step - loss: 0.3406 - accuracy: 0.8735 - precision: 0.6280 - recall: 0.0852\n",
      "Epoch 197/250\n",
      "185/185 [==============================] - 0s 835us/step - loss: 0.3358 - accuracy: 0.8754 - precision: 0.7027 - recall: 0.0860\n",
      "Epoch 198/250\n",
      "185/185 [==============================] - 0s 798us/step - loss: 0.3323 - accuracy: 0.8764 - precision: 0.7379 - recall: 0.0885\n",
      "Epoch 199/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.3338 - accuracy: 0.8770 - precision: 0.7622 - recall: 0.0902\n",
      "Epoch 200/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3339 - accuracy: 0.8761 - precision: 0.7463 - recall: 0.0827\n",
      "Epoch 201/250\n",
      "185/185 [==============================] - 0s 794us/step - loss: 0.3350 - accuracy: 0.8752 - precision: 0.6747 - recall: 0.0926\n",
      "Epoch 202/250\n",
      "185/185 [==============================] - 0s 904us/step - loss: 0.3349 - accuracy: 0.8757 - precision: 0.6909 - recall: 0.0943\n",
      "Epoch 203/250\n",
      "185/185 [==============================] - 0s 855us/step - loss: 0.3321 - accuracy: 0.8778 - precision: 0.7770 - recall: 0.0951\n",
      "Epoch 204/250\n",
      "185/185 [==============================] - 0s 796us/step - loss: 0.3331 - accuracy: 0.8770 - precision: 0.7329 - recall: 0.0976\n",
      "Epoch 205/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.3339 - accuracy: 0.8778 - precision: 0.7662 - recall: 0.0976\n",
      "Epoch 206/250\n",
      "185/185 [==============================] - 0s 812us/step - loss: 0.3275 - accuracy: 0.8775 - precision: 0.7801 - recall: 0.0910\n",
      "Epoch 207/250\n",
      "185/185 [==============================] - 0s 816us/step - loss: 0.3269 - accuracy: 0.8766 - precision: 0.7029 - recall: 0.1017\n",
      "Epoch 208/250\n",
      "185/185 [==============================] - 0s 883us/step - loss: 0.3270 - accuracy: 0.8786 - precision: 0.7871 - recall: 0.1009\n",
      "Epoch 209/250\n",
      "185/185 [==============================] - 0s 846us/step - loss: 0.3308 - accuracy: 0.8772 - precision: 0.7375 - recall: 0.0976\n",
      "Epoch 210/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3287 - accuracy: 0.8776 - precision: 0.7410 - recall: 0.1017\n",
      "Epoch 211/250\n",
      "185/185 [==============================] - 0s 863us/step - loss: 0.3256 - accuracy: 0.8770 - precision: 0.7273 - recall: 0.0993\n",
      "Epoch 212/250\n",
      "185/185 [==============================] - 0s 876us/step - loss: 0.3369 - accuracy: 0.8763 - precision: 0.6650 - recall: 0.1133\n",
      "Epoch 213/250\n",
      "185/185 [==============================] - 0s 821us/step - loss: 0.3277 - accuracy: 0.8776 - precision: 0.7222 - recall: 0.1075\n",
      "Epoch 214/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.3292 - accuracy: 0.8781 - precision: 0.7322 - recall: 0.1108\n",
      "Epoch 215/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3265 - accuracy: 0.8791 - precision: 0.7640 - recall: 0.1125\n",
      "Epoch 216/250\n",
      "185/185 [==============================] - 0s 880us/step - loss: 0.3260 - accuracy: 0.8786 - precision: 0.7665 - recall: 0.1059\n",
      "Epoch 217/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.3243 - accuracy: 0.8788 - precision: 0.7486 - recall: 0.1133\n",
      "Epoch 218/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.3240 - accuracy: 0.8786 - precision: 0.7543 - recall: 0.1092\n",
      "Epoch 219/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.3252 - accuracy: 0.8795 - precision: 0.7552 - recall: 0.1199\n",
      "Epoch 220/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.3226 - accuracy: 0.8781 - precision: 0.7225 - recall: 0.1141\n",
      "Epoch 221/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3263 - accuracy: 0.8786 - precision: 0.7330 - recall: 0.1158\n",
      "Epoch 222/250\n",
      "185/185 [==============================] - 0s 912us/step - loss: 0.3222 - accuracy: 0.8783 - precision: 0.7458 - recall: 0.1092\n",
      "Epoch 223/250\n",
      "185/185 [==============================] - 0s 839us/step - loss: 0.3225 - accuracy: 0.8776 - precision: 0.7128 - recall: 0.1108\n",
      "Epoch 224/250\n",
      "185/185 [==============================] - 0s 817us/step - loss: 0.3232 - accuracy: 0.8801 - precision: 0.7512 - recall: 0.1274\n",
      "Epoch 225/250\n",
      "185/185 [==============================] - 0s 921us/step - loss: 0.3238 - accuracy: 0.8792 - precision: 0.7624 - recall: 0.1141\n",
      "Epoch 226/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.3184 - accuracy: 0.8795 - precision: 0.7526 - recall: 0.1208\n",
      "Epoch 227/250\n",
      "185/185 [==============================] - 0s 904us/step - loss: 0.3214 - accuracy: 0.8814 - precision: 0.8177 - recall: 0.1224\n",
      "Epoch 228/250\n",
      "185/185 [==============================] - 0s 843us/step - loss: 0.3167 - accuracy: 0.8806 - precision: 0.7967 - recall: 0.1199\n",
      "Epoch 229/250\n",
      "185/185 [==============================] - 0s 871us/step - loss: 0.3195 - accuracy: 0.8792 - precision: 0.7295 - recall: 0.1249\n",
      "Epoch 230/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.3213 - accuracy: 0.8788 - precision: 0.7241 - recall: 0.1216\n",
      "Epoch 231/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 807us/step - loss: 0.3248 - accuracy: 0.8773 - precision: 0.6808 - recall: 0.1199\n",
      "Epoch 232/250\n",
      "185/185 [==============================] - 0s 835us/step - loss: 0.3192 - accuracy: 0.8790 - precision: 0.7163 - recall: 0.1274\n",
      "Epoch 233/250\n",
      "185/185 [==============================] - 0s 866us/step - loss: 0.3183 - accuracy: 0.8811 - precision: 0.7772 - recall: 0.1299\n",
      "Epoch 234/250\n",
      "185/185 [==============================] - 0s 841us/step - loss: 0.3164 - accuracy: 0.8811 - precision: 0.7593 - recall: 0.1356\n",
      "Epoch 235/250\n",
      "185/185 [==============================] - 0s 810us/step - loss: 0.3154 - accuracy: 0.8802 - precision: 0.7857 - recall: 0.1183\n",
      "Epoch 236/250\n",
      "185/185 [==============================] - 0s 859us/step - loss: 0.3187 - accuracy: 0.8804 - precision: 0.7431 - recall: 0.1340\n",
      "Epoch 237/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3145 - accuracy: 0.8800 - precision: 0.7656 - recall: 0.1216\n",
      "Epoch 238/250\n",
      "185/185 [==============================] - 0s 916us/step - loss: 0.3122 - accuracy: 0.8819 - precision: 0.7857 - recall: 0.1365\n",
      "Epoch 239/250\n",
      "185/185 [==============================] - 0s 859us/step - loss: 0.3152 - accuracy: 0.8819 - precision: 0.7655 - recall: 0.1431\n",
      "Epoch 240/250\n",
      "185/185 [==============================] - 0s 858us/step - loss: 0.3172 - accuracy: 0.8808 - precision: 0.7670 - recall: 0.1307\n",
      "Epoch 241/250\n",
      "185/185 [==============================] - 0s 867us/step - loss: 0.3152 - accuracy: 0.8819 - precision: 0.7752 - recall: 0.1398\n",
      "Epoch 242/250\n",
      "185/185 [==============================] - 0s 829us/step - loss: 0.3130 - accuracy: 0.8830 - precision: 0.8125 - recall: 0.1398\n",
      "Epoch 243/250\n",
      "185/185 [==============================] - 0s 923us/step - loss: 0.3093 - accuracy: 0.8840 - precision: 0.8528 - recall: 0.1390\n",
      "Epoch 244/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3114 - accuracy: 0.8806 - precision: 0.7647 - recall: 0.1290\n",
      "Epoch 245/250\n",
      "185/185 [==============================] - 0s 902us/step - loss: 0.3103 - accuracy: 0.8841 - precision: 0.8182 - recall: 0.1489\n",
      "Epoch 246/250\n",
      "185/185 [==============================] - 0s 916us/step - loss: 0.3134 - accuracy: 0.8807 - precision: 0.7380 - recall: 0.1398\n",
      "Epoch 247/250\n",
      "185/185 [==============================] - 0s 879us/step - loss: 0.3093 - accuracy: 0.8830 - precision: 0.7708 - recall: 0.1530\n",
      "Epoch 248/250\n",
      "185/185 [==============================] - 0s 868us/step - loss: 0.3074 - accuracy: 0.8823 - precision: 0.7783 - recall: 0.1423\n",
      "Epoch 249/250\n",
      "185/185 [==============================] - 0s 864us/step - loss: 0.3058 - accuracy: 0.8833 - precision: 0.8009 - recall: 0.1464\n",
      "Epoch 250/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.3072 - accuracy: 0.8820 - precision: 0.7510 - recall: 0.1497\n",
      "289/289 [==============================] - 0s 533us/step - loss: 0.2950 - accuracy: 0.8859 - precision: 0.8905 - recall: 0.1481\n",
      "Accuracy: 88.59\n",
      "precision: 89.05\n",
      "recall rate: 14.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "X = np.array(CT_Data)\n",
    "\n",
    "X = X.T\n",
    "X = X.astype(float)\n",
    "y = np.array(Outcome_Data[21])\n",
    "y = y.astype(int)\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=11, use_bias=True))\n",
    "model.add(Dense(64, activation='relu',use_bias=True))\n",
    "model.add(Dense(128, activation='relu',use_bias=True))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy','Precision','Recall'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=250, batch_size=50)\n",
    "# evaluate the keras model\n",
    "_, accuracy,precision,recall = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('precision: %.2f' % (precision*100))\n",
    "print('recall rate: %.2f' % (recall*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(9223, 1)\n",
      "8171\n",
      "1052\n",
      "179\n",
      "validation accuracy is: 0.8859373305865771. Successfully detected cancer: 179\n",
      "precision score is: 89.0547%\n",
      "recall_score is: 14.8056%\n",
      "f1_score: 25.3901%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_y = model.predict(X)\n",
    "print(X.shape)\n",
    "print(test_y.shape)\n",
    "test_y = test_y > 0.5\n",
    "right_count = 0\n",
    "wrong_count = 0\n",
    "cancer_dectected = 0\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == y[i]:\n",
    "        right_count = right_count + 1\n",
    "        if test_y[i] == True:\n",
    "            cancer_dectected = cancer_dectected + 1\n",
    "    else:\n",
    "        wrong_count = wrong_count + 1\n",
    "print(right_count)\n",
    "print(wrong_count)\n",
    "print(cancer_dectected)\n",
    "print(\"validation accuracy is: \"+str(right_count / (right_count + wrong_count)) + \". Successfully detected cancer: \"+str(cancer_dectected))\n",
    "print(\"precision score is: {0:.4%}\".format(precision_score(y, test_y)))\n",
    "print(\"recall_score is: {0:.4%}\".format(recall_score(y, test_y)))\n",
    "print(\"f1_score: {0:.4%}\".format(f1_score(y, test_y)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
