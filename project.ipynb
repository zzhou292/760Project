{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "from pandas import *\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading\n",
    " \n",
    "# reading CSV file\n",
    "data = read_csv(\"data_input/OppScrData.csv\",keep_default_na=False,low_memory=False)\n",
    "\n",
    "# ======================= Clinic Data =====================================\n",
    "Clinic_Data = []\n",
    "Clinic_Data.append(data['Record ID'].tolist())                                          # Col A\n",
    "Clinic_Data.append(data['Visit ID'].tolist())                                           # Col B\n",
    "Clinic_Data.append(data['PT ID'].tolist())                                              # Col C\n",
    "Clinic_Data.append(data['Clinical F/U interval  [d from CT]'].tolist())                 # Col D\n",
    "Clinic_Data.append(data['BMI'].tolist())                                                # Col E\n",
    "Clinic_Data.append(data['BMI >30'].tolist())                                            # Col F\n",
    "Clinic_Data.append(data['Sex'].tolist())                                                # Col G\n",
    "Clinic_Data.append(data['Age at CT'].tolist())                                          # Col H\n",
    "Clinic_Data.append(data['Tobacco'].tolist())                                            # Col I\n",
    "Clinic_Data.append(data['Alcohol abuse'].tolist())                                      # Col J\n",
    "Clinic_Data.append(data['FRS 10-year risk (%)'].tolist())                               # Col K\n",
    "Clinic_Data.append(data['FRAX 10y Fx Prob (Orange-w/ DXA)'].tolist())                   # Col L\n",
    "Clinic_Data.append(data['FRAX 10y Hip Fx Prob (Orange-w/ DXA)'].tolist())               # Col M\n",
    "Clinic_Data.append(data['Met Sx'].tolist())                                             # Col N\n",
    "\n",
    "# ======================= Outcome Data =====================================\n",
    "Outcome_Data = []\n",
    "Outcome_Data.append(data['DEATH [d from CT]'].tolist())                                 # Col P\n",
    "Outcome_Data.append(data['CVD DX'].tolist())                                            # Col Q\n",
    "Outcome_Data.append(data['CVD DX Date [d from CT]'].tolist())                           # Col R\n",
    "Outcome_Data.append(data['Heart failure DX'].tolist())                                  # Col S\n",
    "Outcome_Data.append(data['Heart failure DX Date [d from CT]'].tolist())                 # Col T\n",
    "Outcome_Data.append(data['MI DX'].tolist())                                             # Col U\n",
    "Outcome_Data.append(data['MI DX Date [d from CT]'].tolist())                            # Col V\n",
    "Outcome_Data.append(data['Type 2 Diabetes DX'].tolist())                                # Col W\n",
    "Outcome_Data.append(data['Type 2 Diabetes DX Date [d from CT]'].tolist())               # Col X\n",
    "Outcome_Data.append(data['Femoral neck fracture DX'].tolist())                          # Col Y\n",
    "Outcome_Data.append(data['Femoral neck fracture DX Date [d from CT]'].tolist())         # Col Z\n",
    "Outcome_Data.append(data['Unspec femoral fracture DX'].tolist())                        # Col AA\n",
    "Outcome_Data.append(data['Unspec femoral fracture DX Date [d from CT]'].tolist())       # Col AB\n",
    "Outcome_Data.append(data['Forearm fracture DX'].tolist())                               # Col AC\n",
    "Outcome_Data.append(data['Forearm fracture DX Date [d from CT]'].tolist())              # Col AD\n",
    "Outcome_Data.append(data['Humerus fracture DX'].tolist())                               # Col AE\n",
    "Outcome_Data.append(data['Humerus fracture DX Date [d from CT]'].tolist())              # Col AF\n",
    "Outcome_Data.append(data['Pathologic fracture DX'].tolist())                            # Col AG\n",
    "Outcome_Data.append(data['Pathologic fracture DX Date [d from CT]'].tolist())           # Col AH\n",
    "Outcome_Data.append(data['Alzheimers DX'].tolist())                                     # Col AI\n",
    "Outcome_Data.append(data['Alzheimers DX Date [d from CT]'].tolist())                    # Col AJ\n",
    "Outcome_Data.append(data['Primary Cancer Site'].tolist())                               # Col AK\n",
    "Outcome_Data.append(data['Primary Cancer Dx [d from CT]'].tolist())                      # Col AL\n",
    "Outcome_Data.append(data['Primary Cancer Site 2'].tolist())                             # Col AM\n",
    "Outcome_Data.append(data['Primary Cancer Site 2 Dx [d from CT]'].tolist())              # Col AN\n",
    "\n",
    "# ======================= CT Data =====================================\n",
    "CT_Data = []\n",
    "CT_Data.append(data['L1_HU_BMD'].tolist())                                              # Col AP\n",
    "CT_Data.append(data['TAT Area (cm2)'].tolist())                                         # Col AQ\n",
    "CT_Data.append(data['Total Body                Area EA (cm2)'].tolist())                # Col AR\n",
    "CT_Data.append(data['VAT Area (cm2)'].tolist())                                         # Col AS\n",
    "CT_Data.append(data['SAT Area (cm2)'].tolist())                                         # Col AT\n",
    "CT_Data.append(data['VAT/SAT     Ratio'].tolist())                                      # Col AU\n",
    "CT_Data.append(data['Muscle HU'].tolist())                                              # Col AV\n",
    "CT_Data.append(data[' Muscle Area (cm2)'].tolist())                                     # Col AW\n",
    "CT_Data.append(data['L3 SMI (cm2/m2)'].tolist())                                        # Col AX\n",
    "CT_Data.append(data['AoCa        Agatston'].tolist())                                   # Col AY\n",
    "CT_Data.append(data['Liver HU    (Median)'].tolist())                                   # Col AZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= Clinic Data =====================================\n",
    "# BMI - If BMI is unknown, we assign an average BMI value\n",
    "average_BMI = mean([float(l) for l in Clinic_Data[4] if l!=''])\n",
    "for i in range(len(Clinic_Data[4])):\n",
    "    if Clinic_Data[4][i] == '' or Clinic_Data[4][i] == ' ':\n",
    "        Clinic_Data[4][i] = average_BMI\n",
    "\n",
    "# BMI >30 - 0 for N, 1 for Y\n",
    "for i in range(len(Clinic_Data[5])):\n",
    "    if Clinic_Data[5][i] == 'N':\n",
    "        Clinic_Data[5][i] = 0\n",
    "    elif Clinic_Data[5][i] == 'Y':\n",
    "        Clinic_Data[5][i] = 1\n",
    "    else:\n",
    "        if float(Clinic_Data[4][i]) > 30:\n",
    "            Clinic_Data[5][i] = 1\n",
    "        else:\n",
    "            Clinic_Data[5][i] = 0\n",
    "\n",
    "\n",
    "# Sex - 0 for female, 1 for male\n",
    "for i in range(len(Clinic_Data[6])):\n",
    "    if Clinic_Data[6][i] == 'Female':\n",
    "        Clinic_Data[6][i] = 0\n",
    "    elif Clinic_Data[6][i] == 'Male':\n",
    "        Clinic_Data[6][i] = 1\n",
    "\n",
    "# Tobacco - -1 for 'No', 1 for 'Yes', 0 for unknown\n",
    "for i in range(len(Clinic_Data[8])):\n",
    "    if Clinic_Data[8][i] == 'Yes':\n",
    "        Clinic_Data[8][i] = 1\n",
    "    elif Clinic_Data[8][i] == 'No':\n",
    "        Clinic_Data[8][i] = -1\n",
    "    else:\n",
    "        Clinic_Data[8][i] = 0\n",
    "\n",
    "# Alcohol Abuse\n",
    "# We categorize alcohol abuse into several levels:\n",
    "# 5 - Acute alcoholic intoxicational alcoholism\n",
    "# 4 - Alcohol abuse\n",
    "# 3 - Alcohol dependence\n",
    "# 2 - Alcohol use\n",
    "# 1 - Other and unspecified\n",
    "for i in range(len(Clinic_Data[9])):\n",
    "    if Clinic_Data[9][i] == 'Acutealcoholicintoxicationinalcoholism,continuous' or Clinic_Data[9][i] == 'Acutealcoholicintoxicationinalcoholism,unspecified':\n",
    "        Clinic_Data[9][i] = 5\n",
    "    elif Clinic_Data[9][i] == 'Alcoholabuse,uncomplicated' or Clinic_Data[9][i] == 'Alcoholabuse,inremission' or Clinic_Data[9][i] == 'Alcoholabusewithintoxication,unspecified' or Clinic_Data[9][i] == 'Alcoholabusewithotheralcohol-induceddisorder':\n",
    "        Clinic_Data[9][i] = 4\n",
    "    elif Clinic_Data[9][i] == 'Alcoholdependence,uncomplicated' or Clinic_Data[9][i] == 'Alcoholdependence,inremission' or Clinic_Data[9][i] == 'Alcoholdependencewithwithdrawal,unspecified' or Clinic_Data[9][i] == 'Alcoholdependencewithintoxication,unspecified' or Clinic_Data[9][i]=='Alcoholdependencewithwithdrawaldelirium':\n",
    "        Clinic_Data[9][i] = 3\n",
    "    elif Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithintoxication,uncomplicated' or Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithunspecifiedalcohol-induceddisorder' or Clinic_Data[9][i] == 'Alcoholuse,unspecifiedwithalcohol-inducedsleepdisorder':\n",
    "        Clinic_Data[9][i] = 2\n",
    "    elif Clinic_Data[9][i] == 'Otherandunspecifiedalcoholdependence,unspecifieddrinkingbehavior' or Clinic_Data[9][i] == 'Otherandunspecifiedalcoholdependence,continuousdrinkingbehavior' or Clinic_Data[9][i]=='Otherandunspecifiedalcoholdependence,inremission' or Clinic_Data[9][i]=='Otherandunspecifiedalcoholdependence,episodicdrinkingbehavior':\n",
    "        Clinic_Data[9][i] = 1\n",
    "    elif Clinic_Data[9][i] == '' or Clinic_Data[9][i] == ' ':\n",
    "        Clinic_Data[9][i] = 0\n",
    "\n",
    "# FRS 10-year Risk\n",
    "# TODO\n",
    "# we consider <1 to be 0.005, >30 to be 0.4, if unknown then we give 0\n",
    "for i in range(len(Clinic_Data[10])):\n",
    "    if Clinic_Data[10][i] == '<1%':\n",
    "        Clinic_Data[10][i] = 0.005\n",
    "    elif Clinic_Data[10][i] == '>30%':\n",
    "        Clinic_Data[10][i] = 0.4\n",
    "    elif Clinic_Data[10][i] == 'X':\n",
    "        Clinic_Data[10][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[10][i] = float(Clinic_Data[10][i].strip('%'))/100\n",
    "\n",
    "# FRAX 10y Fx Prob (Orange-w/ DXA)\n",
    "# FRAX 10y Hip Fx Prob (Orange-w/ DXA)\n",
    "# convert '_' to 0 for both columns\n",
    "for i in range(len(Clinic_Data[11])):\n",
    "    if Clinic_Data[11][i] == '_':\n",
    "        Clinic_Data[11][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[11][i] = float(Clinic_Data[11][i])\n",
    "    \n",
    "for i in range(len(Clinic_Data[12])):\n",
    "    if Clinic_Data[12][i] == '_':\n",
    "        Clinic_Data[12][i] = 0\n",
    "    else:\n",
    "        Clinic_Data[12][i] = float(Clinic_Data[12][i])\n",
    "\n",
    "# Met Sx\n",
    "# set -1 if 'N', set 1 if 'Y', set 0 if unknown\n",
    "for i in range(len(Clinic_Data[13])):\n",
    "    if Clinic_Data[13][i] == '' or Clinic_Data[13][i] == ' ':\n",
    "        Clinic_Data[13][i] = 0\n",
    "    elif Clinic_Data[13][i] == 'N':\n",
    "        Clinic_Data[13][i] = -1\n",
    "    elif Clinic_Data[13][i] == 'Y':\n",
    "        Clinic_Data[13][i] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average(list):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for i in range(len(list)):\n",
    "        if list[i]!='' and list[i]!=' ':\n",
    "            sum = sum + float(list[i])\n",
    "            count = count + 1\n",
    "    \n",
    "    if count!= 0:\n",
    "        return sum/count\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= CT Data =====================================\n",
    "# fill in unknowns with mean value of all known fields\n",
    "for i in range(len(CT_Data)):\n",
    "    average = compute_average(CT_Data[i])\n",
    "    for j in range(len(CT_Data[i])):\n",
    "        if CT_Data[i][j] == '' or CT_Data[i][j] == ' ':\n",
    "            CT_Data[i][j] = average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# ======================= Clinical Data =====================================\n",
    "for i in range(len(Outcome_Data)):\n",
    "    for j in range(len(Outcome_Data[i])):\n",
    "        if Outcome_Data[i][j] == '' or Outcome_Data[i][j] == ' ':\n",
    "            Outcome_Data[i][j] = 0\n",
    "        else:\n",
    "            Outcome_Data[i][j] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "185/185 [==============================] - 1s 821us/step - loss: 1.8577 - accuracy: 0.7964 - precision: 0.1453 - recall: 0.1133\n",
      "Epoch 2/250\n",
      "185/185 [==============================] - 0s 791us/step - loss: 0.7135 - accuracy: 0.8248 - precision: 0.1921 - recall: 0.1050\n",
      "Epoch 3/250\n",
      "185/185 [==============================] - 0s 817us/step - loss: 0.8177 - accuracy: 0.8190 - precision: 0.1751 - recall: 0.1026\n",
      "Epoch 4/250\n",
      "185/185 [==============================] - 0s 821us/step - loss: 0.6708 - accuracy: 0.8310 - precision: 0.1930 - recall: 0.0910\n",
      "Epoch 5/250\n",
      "185/185 [==============================] - 0s 825us/step - loss: 0.7022 - accuracy: 0.8253 - precision: 0.1694 - recall: 0.0852\n",
      "Epoch 6/250\n",
      "185/185 [==============================] - 0s 791us/step - loss: 0.5888 - accuracy: 0.8355 - precision: 0.2072 - recall: 0.0902\n",
      "Epoch 7/250\n",
      "185/185 [==============================] - 0s 860us/step - loss: 0.6359 - accuracy: 0.8367 - precision: 0.2048 - recall: 0.0852\n",
      "Epoch 8/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.6842 - accuracy: 0.8289 - precision: 0.1930 - recall: 0.0959\n",
      "Epoch 9/250\n",
      "185/185 [==============================] - 0s 858us/step - loss: 0.6065 - accuracy: 0.8408 - precision: 0.1953 - recall: 0.0687\n",
      "Epoch 10/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.5941 - accuracy: 0.8353 - precision: 0.1850 - recall: 0.0753\n",
      "Epoch 11/250\n",
      "185/185 [==============================] - 0s 752us/step - loss: 0.5808 - accuracy: 0.8389 - precision: 0.1969 - recall: 0.0744\n",
      "Epoch 12/250\n",
      "185/185 [==============================] - 0s 820us/step - loss: 0.5998 - accuracy: 0.8330 - precision: 0.1799 - recall: 0.0769\n",
      "Epoch 13/250\n",
      "185/185 [==============================] - 0s 829us/step - loss: 0.7564 - accuracy: 0.8309 - precision: 0.1792 - recall: 0.0811\n",
      "Epoch 14/250\n",
      "185/185 [==============================] - 0s 814us/step - loss: 0.6769 - accuracy: 0.8325 - precision: 0.2143 - recall: 0.1042\n",
      "Epoch 15/250\n",
      "185/185 [==============================] - 0s 839us/step - loss: 0.6550 - accuracy: 0.8336 - precision: 0.1753 - recall: 0.0728\n",
      "Epoch 16/250\n",
      "185/185 [==============================] - 0s 824us/step - loss: 0.7850 - accuracy: 0.8276 - precision: 0.2100 - recall: 0.1141\n",
      "Epoch 17/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.5800 - accuracy: 0.8400 - precision: 0.2000 - recall: 0.0736\n",
      "Epoch 18/250\n",
      "185/185 [==============================] - 0s 805us/step - loss: 0.6214 - accuracy: 0.8331 - precision: 0.1827 - recall: 0.0786\n",
      "Epoch 19/250\n",
      "185/185 [==============================] - 0s 923us/step - loss: 0.5420 - accuracy: 0.8433 - precision: 0.1974 - recall: 0.0637\n",
      "Epoch 20/250\n",
      "185/185 [==============================] - 0s 923us/step - loss: 0.5502 - accuracy: 0.8452 - precision: 0.2411 - recall: 0.0844\n",
      "Epoch 21/250\n",
      "185/185 [==============================] - 0s 933us/step - loss: 0.6279 - accuracy: 0.8364 - precision: 0.1875 - recall: 0.0744\n",
      "Epoch 22/250\n",
      "185/185 [==============================] - 0s 903us/step - loss: 0.5688 - accuracy: 0.8456 - precision: 0.2359 - recall: 0.0794\n",
      "Epoch 23/250\n",
      "185/185 [==============================] - 0s 862us/step - loss: 0.5852 - accuracy: 0.8386 - precision: 0.2034 - recall: 0.0794\n",
      "Epoch 24/250\n",
      "185/185 [==============================] - 0s 871us/step - loss: 0.5329 - accuracy: 0.8473 - precision: 0.2388 - recall: 0.0753\n",
      "Epoch 25/250\n",
      "185/185 [==============================] - 0s 889us/step - loss: 0.5891 - accuracy: 0.8421 - precision: 0.2286 - recall: 0.0860\n",
      "Epoch 26/250\n",
      "185/185 [==============================] - 0s 802us/step - loss: 0.5159 - accuracy: 0.8470 - precision: 0.1994 - recall: 0.0554\n",
      "Epoch 27/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.4863 - accuracy: 0.8512 - precision: 0.2379 - recall: 0.0612\n",
      "Epoch 28/250\n",
      "185/185 [==============================] - 0s 899us/step - loss: 0.5217 - accuracy: 0.8428 - precision: 0.2068 - recall: 0.0703\n",
      "Epoch 29/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.6472 - accuracy: 0.8382 - precision: 0.2008 - recall: 0.0786\n",
      "Epoch 30/250\n",
      "185/185 [==============================] - 0s 879us/step - loss: 0.5709 - accuracy: 0.8447 - precision: 0.2191 - recall: 0.0720\n",
      "Epoch 31/250\n",
      "185/185 [==============================] - 0s 831us/step - loss: 0.5771 - accuracy: 0.8448 - precision: 0.2407 - recall: 0.0852\n",
      "Epoch 32/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.5602 - accuracy: 0.8458 - precision: 0.2234 - recall: 0.0711\n",
      "Epoch 33/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.5262 - accuracy: 0.8474 - precision: 0.2474 - recall: 0.0802\n",
      "Epoch 34/250\n",
      "185/185 [==============================] - 0s 908us/step - loss: 0.5146 - accuracy: 0.8474 - precision: 0.2071 - recall: 0.0579\n",
      "Epoch 35/250\n",
      "185/185 [==============================] - 0s 928us/step - loss: 0.5891 - accuracy: 0.8381 - precision: 0.2029 - recall: 0.0802\n",
      "Epoch 36/250\n",
      "185/185 [==============================] - 0s 907us/step - loss: 0.5368 - accuracy: 0.8460 - precision: 0.2343 - recall: 0.0769\n",
      "Epoch 37/250\n",
      "185/185 [==============================] - 0s 891us/step - loss: 0.6057 - accuracy: 0.8375 - precision: 0.1928 - recall: 0.0753\n",
      "Epoch 38/250\n",
      "185/185 [==============================] - 0s 866us/step - loss: 0.4721 - accuracy: 0.8508 - precision: 0.2382 - recall: 0.0629\n",
      "Epoch 39/250\n",
      "185/185 [==============================] - 0s 876us/step - loss: 0.5529 - accuracy: 0.8497 - precision: 0.2435 - recall: 0.0695\n",
      "Epoch 40/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.5331 - accuracy: 0.8451 - precision: 0.2222 - recall: 0.0728\n",
      "Epoch 41/250\n",
      "185/185 [==============================] - 0s 805us/step - loss: 0.5075 - accuracy: 0.8464 - precision: 0.2158 - recall: 0.0653\n",
      "Epoch 42/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.5011 - accuracy: 0.8497 - precision: 0.2615 - recall: 0.0802\n",
      "Epoch 43/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.4762 - accuracy: 0.8533 - precision: 0.2500 - recall: 0.0596\n",
      "Epoch 44/250\n",
      "185/185 [==============================] - 0s 916us/step - loss: 0.5024 - accuracy: 0.8474 - precision: 0.2250 - recall: 0.0670\n",
      "Epoch 45/250\n",
      "185/185 [==============================] - 0s 811us/step - loss: 0.4731 - accuracy: 0.8523 - precision: 0.2492 - recall: 0.0629\n",
      "Epoch 46/250\n",
      "185/185 [==============================] - 0s 873us/step - loss: 0.5049 - accuracy: 0.8481 - precision: 0.2209 - recall: 0.0629\n",
      "Epoch 47/250\n",
      "185/185 [==============================] - 0s 888us/step - loss: 0.5002 - accuracy: 0.8517 - precision: 0.2613 - recall: 0.0720\n",
      "Epoch 48/250\n",
      "185/185 [==============================] - 0s 928us/step - loss: 0.5340 - accuracy: 0.8480 - precision: 0.2494 - recall: 0.0794\n",
      "Epoch 49/250\n",
      "185/185 [==============================] - 0s 914us/step - loss: 0.4743 - accuracy: 0.8508 - precision: 0.2262 - recall: 0.0571\n",
      "Epoch 50/250\n",
      "185/185 [==============================] - 0s 909us/step - loss: 0.5050 - accuracy: 0.8481 - precision: 0.2288 - recall: 0.0670\n",
      "Epoch 51/250\n",
      "185/185 [==============================] - 0s 823us/step - loss: 0.4507 - accuracy: 0.8576 - precision: 0.2903 - recall: 0.0596\n",
      "Epoch 52/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.4736 - accuracy: 0.8517 - precision: 0.2492 - recall: 0.0653\n",
      "Epoch 53/250\n",
      "185/185 [==============================] - 0s 899us/step - loss: 0.4736 - accuracy: 0.8536 - precision: 0.2526 - recall: 0.0596\n",
      "Epoch 54/250\n",
      "185/185 [==============================] - 0s 869us/step - loss: 0.4289 - accuracy: 0.8609 - precision: 0.3363 - recall: 0.0629\n",
      "Epoch 55/250\n",
      "185/185 [==============================] - 0s 884us/step - loss: 0.4887 - accuracy: 0.8516 - precision: 0.2727 - recall: 0.0794\n",
      "Epoch 56/250\n",
      "185/185 [==============================] - 0s 884us/step - loss: 0.5137 - accuracy: 0.8510 - precision: 0.2381 - recall: 0.0620\n",
      "Epoch 57/250\n",
      "185/185 [==============================] - 0s 795us/step - loss: 0.4993 - accuracy: 0.8524 - precision: 0.2625 - recall: 0.0695\n",
      "Epoch 58/250\n",
      "185/185 [==============================] - 0s 914us/step - loss: 0.4599 - accuracy: 0.8537 - precision: 0.2500 - recall: 0.0579\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 923us/step - loss: 0.4583 - accuracy: 0.8587 - precision: 0.3259 - recall: 0.0728\n",
      "Epoch 60/250\n",
      "185/185 [==============================] - 0s 910us/step - loss: 0.4605 - accuracy: 0.8575 - precision: 0.3034 - recall: 0.0670\n",
      "Epoch 61/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.4430 - accuracy: 0.8598 - precision: 0.3279 - recall: 0.0662\n",
      "Epoch 62/250\n",
      "185/185 [==============================] - 0s 817us/step - loss: 0.4649 - accuracy: 0.8533 - precision: 0.2707 - recall: 0.0703\n",
      "Epoch 63/250\n",
      "185/185 [==============================] - 0s 883us/step - loss: 0.4366 - accuracy: 0.8583 - precision: 0.2924 - recall: 0.0571\n",
      "Epoch 64/250\n",
      "185/185 [==============================] - 0s 897us/step - loss: 0.4263 - accuracy: 0.8593 - precision: 0.3169 - recall: 0.0637\n",
      "Epoch 65/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.4894 - accuracy: 0.8524 - precision: 0.2625 - recall: 0.0695\n",
      "Epoch 66/250\n",
      "185/185 [==============================] - 0s 873us/step - loss: 0.4097 - accuracy: 0.8594 - precision: 0.2982 - recall: 0.0538\n",
      "Epoch 67/250\n",
      "185/185 [==============================] - 0s 886us/step - loss: 0.4273 - accuracy: 0.8585 - precision: 0.3154 - recall: 0.0678\n",
      "Epoch 68/250\n",
      "185/185 [==============================] - 0s 797us/step - loss: 0.4215 - accuracy: 0.8596 - precision: 0.3045 - recall: 0.0554\n",
      "Epoch 69/250\n",
      "185/185 [==============================] - 0s 812us/step - loss: 0.4155 - accuracy: 0.8607 - precision: 0.3273 - recall: 0.0596\n",
      "Epoch 70/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.4436 - accuracy: 0.8574 - precision: 0.2962 - recall: 0.0637\n",
      "Epoch 71/250\n",
      "185/185 [==============================] - 0s 905us/step - loss: 0.4692 - accuracy: 0.8523 - precision: 0.2424 - recall: 0.0596\n",
      "Epoch 72/250\n",
      "185/185 [==============================] - 0s 886us/step - loss: 0.4321 - accuracy: 0.8572 - precision: 0.2840 - recall: 0.0587\n",
      "Epoch 73/250\n",
      "185/185 [==============================] - 0s 918us/step - loss: 0.4582 - accuracy: 0.8559 - precision: 0.2521 - recall: 0.0505\n",
      "Epoch 74/250\n",
      "185/185 [==============================] - 0s 909us/step - loss: 0.4580 - accuracy: 0.8554 - precision: 0.2896 - recall: 0.0711\n",
      "Epoch 75/250\n",
      "185/185 [==============================] - 0s 872us/step - loss: 0.4509 - accuracy: 0.8553 - precision: 0.2701 - recall: 0.0612\n",
      "Epoch 76/250\n",
      "185/185 [==============================] - 0s 818us/step - loss: 0.4363 - accuracy: 0.8583 - precision: 0.2975 - recall: 0.0596\n",
      "Epoch 77/250\n",
      "185/185 [==============================] - 0s 860us/step - loss: 0.4284 - accuracy: 0.8580 - precision: 0.2905 - recall: 0.0579\n",
      "Epoch 78/250\n",
      "185/185 [==============================] - 0s 828us/step - loss: 0.4155 - accuracy: 0.8612 - precision: 0.3318 - recall: 0.0579\n",
      "Epoch 79/250\n",
      "185/185 [==============================] - 0s 837us/step - loss: 0.4359 - accuracy: 0.8595 - precision: 0.3100 - recall: 0.0587\n",
      "Epoch 80/250\n",
      "185/185 [==============================] - 0s 867us/step - loss: 0.4305 - accuracy: 0.8569 - precision: 0.2576 - recall: 0.0488\n",
      "Epoch 81/250\n",
      "185/185 [==============================] - 0s 903us/step - loss: 0.4612 - accuracy: 0.8536 - precision: 0.2642 - recall: 0.0653\n",
      "Epoch 82/250\n",
      "185/185 [==============================] - 0s 843us/step - loss: 0.4157 - accuracy: 0.8607 - precision: 0.3288 - recall: 0.0604\n",
      "Epoch 83/250\n",
      "185/185 [==============================] - 0s 907us/step - loss: 0.4425 - accuracy: 0.8598 - precision: 0.3264 - recall: 0.0653\n",
      "Epoch 84/250\n",
      "185/185 [==============================] - 0s 890us/step - loss: 0.4130 - accuracy: 0.8624 - precision: 0.3598 - recall: 0.0637\n",
      "Epoch 85/250\n",
      "185/185 [==============================] - 0s 901us/step - loss: 0.4260 - accuracy: 0.8614 - precision: 0.3395 - recall: 0.0604\n",
      "Epoch 86/250\n",
      "185/185 [==============================] - 0s 890us/step - loss: 0.4289 - accuracy: 0.8608 - precision: 0.3518 - recall: 0.0736\n",
      "Epoch 87/250\n",
      "185/185 [==============================] - 0s 841us/step - loss: 0.4116 - accuracy: 0.8618 - precision: 0.3366 - recall: 0.0562\n",
      "Epoch 88/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.4105 - accuracy: 0.8626 - precision: 0.3490 - recall: 0.0554\n",
      "Epoch 89/250\n",
      "185/185 [==============================] - 0s 899us/step - loss: 0.4130 - accuracy: 0.8605 - precision: 0.3010 - recall: 0.0488\n",
      "Epoch 90/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.4013 - accuracy: 0.8641 - precision: 0.3804 - recall: 0.0579\n",
      "Epoch 91/250\n",
      "185/185 [==============================] - 0s 914us/step - loss: 0.4329 - accuracy: 0.8586 - precision: 0.2907 - recall: 0.0546\n",
      "Epoch 92/250\n",
      "185/185 [==============================] - 0s 894us/step - loss: 0.4110 - accuracy: 0.8611 - precision: 0.3269 - recall: 0.0562\n",
      "Epoch 93/250\n",
      "185/185 [==============================] - 0s 880us/step - loss: 0.4096 - accuracy: 0.8618 - precision: 0.3486 - recall: 0.0629\n",
      "Epoch 94/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.3888 - accuracy: 0.8657 - precision: 0.4074 - recall: 0.0546\n",
      "Epoch 95/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.3894 - accuracy: 0.8645 - precision: 0.3772 - recall: 0.0521\n",
      "Epoch 96/250\n",
      "185/185 [==============================] - 0s 828us/step - loss: 0.3976 - accuracy: 0.8638 - precision: 0.3716 - recall: 0.0562\n",
      "Epoch 97/250\n",
      "185/185 [==============================] - 0s 819us/step - loss: 0.4194 - accuracy: 0.8631 - precision: 0.3714 - recall: 0.0645\n",
      "Epoch 98/250\n",
      "185/185 [==============================] - 0s 878us/step - loss: 0.3884 - accuracy: 0.8674 - precision: 0.4583 - recall: 0.0637\n",
      "Epoch 99/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.4057 - accuracy: 0.8623 - precision: 0.3452 - recall: 0.0562\n",
      "Epoch 100/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.4409 - accuracy: 0.8585 - precision: 0.3168 - recall: 0.0687\n",
      "Epoch 101/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.4047 - accuracy: 0.8631 - precision: 0.3594 - recall: 0.0571\n",
      "Epoch 102/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.4299 - accuracy: 0.8586 - precision: 0.3029 - recall: 0.0604\n",
      "Epoch 103/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.3987 - accuracy: 0.8643 - precision: 0.3897 - recall: 0.0629\n",
      "Epoch 104/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.4121 - accuracy: 0.8624 - precision: 0.3485 - recall: 0.0571\n",
      "Epoch 105/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.4017 - accuracy: 0.8630 - precision: 0.3575 - recall: 0.0571\n",
      "Epoch 106/250\n",
      "185/185 [==============================] - 0s 901us/step - loss: 0.4034 - accuracy: 0.8630 - precision: 0.3514 - recall: 0.0538\n",
      "Epoch 107/250\n",
      "185/185 [==============================] - 0s 862us/step - loss: 0.3848 - accuracy: 0.8676 - precision: 0.4492 - recall: 0.0438\n",
      "Epoch 108/250\n",
      "185/185 [==============================] - 0s 807us/step - loss: 0.3814 - accuracy: 0.8670 - precision: 0.4375 - recall: 0.0521\n",
      "Epoch 109/250\n",
      "185/185 [==============================] - 0s 816us/step - loss: 0.3956 - accuracy: 0.8667 - precision: 0.4432 - recall: 0.0645\n",
      "Epoch 110/250\n",
      "185/185 [==============================] - 0s 865us/step - loss: 0.3849 - accuracy: 0.8666 - precision: 0.4364 - recall: 0.0596\n",
      "Epoch 111/250\n",
      "185/185 [==============================] - 0s 834us/step - loss: 0.4009 - accuracy: 0.8615 - precision: 0.3111 - recall: 0.0463\n",
      "Epoch 112/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.3969 - accuracy: 0.8639 - precision: 0.3905 - recall: 0.0678\n",
      "Epoch 113/250\n",
      "185/185 [==============================] - 0s 850us/step - loss: 0.3737 - accuracy: 0.8667 - precision: 0.4367 - recall: 0.0571\n",
      "Epoch 114/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3964 - accuracy: 0.8640 - precision: 0.3858 - recall: 0.0629\n",
      "Epoch 115/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.3799 - accuracy: 0.8671 - precision: 0.4361 - recall: 0.0480\n",
      "Epoch 116/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3905 - accuracy: 0.8656 - precision: 0.4061 - recall: 0.0554\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 867us/step - loss: 0.3821 - accuracy: 0.8639 - precision: 0.3544 - recall: 0.0463\n",
      "Epoch 118/250\n",
      "185/185 [==============================] - 0s 827us/step - loss: 0.3777 - accuracy: 0.8688 - precision: 0.4967 - recall: 0.0629\n",
      "Epoch 119/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3803 - accuracy: 0.8650 - precision: 0.4082 - recall: 0.0662\n",
      "Epoch 120/250\n",
      "185/185 [==============================] - 0s 882us/step - loss: 0.3811 - accuracy: 0.8657 - precision: 0.4074 - recall: 0.0546\n",
      "Epoch 121/250\n",
      "185/185 [==============================] - 0s 901us/step - loss: 0.3845 - accuracy: 0.8657 - precision: 0.4096 - recall: 0.0562\n",
      "Epoch 122/250\n",
      "185/185 [==============================] - 0s 886us/step - loss: 0.3774 - accuracy: 0.8664 - precision: 0.4228 - recall: 0.0521\n",
      "Epoch 123/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.3774 - accuracy: 0.8662 - precision: 0.4101 - recall: 0.0471\n",
      "Epoch 124/250\n",
      "185/185 [==============================] - 0s 911us/step - loss: 0.3780 - accuracy: 0.8660 - precision: 0.4220 - recall: 0.0604\n",
      "Epoch 125/250\n",
      "185/185 [==============================] - 0s 888us/step - loss: 0.3813 - accuracy: 0.8652 - precision: 0.3988 - recall: 0.0554\n",
      "Epoch 126/250\n",
      "185/185 [==============================] - 0s 818us/step - loss: 0.3713 - accuracy: 0.8671 - precision: 0.4351 - recall: 0.0471\n",
      "Epoch 127/250\n",
      "185/185 [==============================] - 0s 819us/step - loss: 0.3718 - accuracy: 0.8679 - precision: 0.4698 - recall: 0.0579\n",
      "Epoch 128/250\n",
      "185/185 [==============================] - 0s 865us/step - loss: 0.3751 - accuracy: 0.8675 - precision: 0.4558 - recall: 0.0554\n",
      "Epoch 129/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3744 - accuracy: 0.8670 - precision: 0.4408 - recall: 0.0554\n",
      "Epoch 130/250\n",
      "185/185 [==============================] - 0s 816us/step - loss: 0.3840 - accuracy: 0.8669 - precision: 0.4463 - recall: 0.0653\n",
      "Epoch 131/250\n",
      "185/185 [==============================] - 0s 820us/step - loss: 0.3702 - accuracy: 0.8676 - precision: 0.4625 - recall: 0.0612\n",
      "Epoch 132/250\n",
      "185/185 [==============================] - 0s 831us/step - loss: 0.3659 - accuracy: 0.8704 - precision: 0.5603 - recall: 0.0538\n",
      "Epoch 133/250\n",
      "185/185 [==============================] - 0s 868us/step - loss: 0.3785 - accuracy: 0.8665 - precision: 0.4433 - recall: 0.0711\n",
      "Epoch 134/250\n",
      "185/185 [==============================] - 0s 823us/step - loss: 0.3754 - accuracy: 0.8687 - precision: 0.4934 - recall: 0.0620\n",
      "Epoch 135/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.3798 - accuracy: 0.8652 - precision: 0.4183 - recall: 0.0720\n",
      "Epoch 136/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3725 - accuracy: 0.8684 - precision: 0.4850 - recall: 0.0670\n",
      "Epoch 137/250\n",
      "185/185 [==============================] - 0s 865us/step - loss: 0.3690 - accuracy: 0.8702 - precision: 0.5417 - recall: 0.0645\n",
      "Epoch 138/250\n",
      "185/185 [==============================] - 0s 850us/step - loss: 0.3690 - accuracy: 0.8689 - precision: 0.5000 - recall: 0.0554\n",
      "Epoch 139/250\n",
      "185/185 [==============================] - 0s 841us/step - loss: 0.3718 - accuracy: 0.8671 - precision: 0.4491 - recall: 0.0620\n",
      "Epoch 140/250\n",
      "185/185 [==============================] - 0s 825us/step - loss: 0.3730 - accuracy: 0.8697 - precision: 0.5226 - recall: 0.0670\n",
      "Epoch 141/250\n",
      "185/185 [==============================] - 0s 851us/step - loss: 0.3601 - accuracy: 0.8703 - precision: 0.5461 - recall: 0.0637\n",
      "Epoch 142/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3571 - accuracy: 0.8704 - precision: 0.5437 - recall: 0.0720\n",
      "Epoch 143/250\n",
      "185/185 [==============================] - 0s 954us/step - loss: 0.3723 - accuracy: 0.8670 - precision: 0.4430 - recall: 0.0579\n",
      "Epoch 144/250\n",
      "185/185 [==============================] - 0s 837us/step - loss: 0.3650 - accuracy: 0.8690 - precision: 0.5030 - recall: 0.0703\n",
      "Epoch 145/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.3885 - accuracy: 0.8673 - precision: 0.4595 - recall: 0.0703\n",
      "Epoch 146/250\n",
      "185/185 [==============================] - 0s 899us/step - loss: 0.3613 - accuracy: 0.8691 - precision: 0.5064 - recall: 0.0653\n",
      "Epoch 147/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.3627 - accuracy: 0.8706 - precision: 0.5500 - recall: 0.0728\n",
      "Epoch 148/250\n",
      "185/185 [==============================] - 0s 901us/step - loss: 0.3617 - accuracy: 0.8706 - precision: 0.5519 - recall: 0.0703\n",
      "Epoch 149/250\n",
      "185/185 [==============================] - 0s 927us/step - loss: 0.3635 - accuracy: 0.8706 - precision: 0.5519 - recall: 0.0703\n",
      "Epoch 150/250\n",
      "185/185 [==============================] - 0s 900us/step - loss: 0.3584 - accuracy: 0.8703 - precision: 0.5394 - recall: 0.0736\n",
      "Epoch 151/250\n",
      "185/185 [==============================] - 0s 890us/step - loss: 0.3635 - accuracy: 0.8693 - precision: 0.5122 - recall: 0.0695\n",
      "Epoch 152/250\n",
      "185/185 [==============================] - 0s 821us/step - loss: 0.3559 - accuracy: 0.8712 - precision: 0.5669 - recall: 0.0736\n",
      "Epoch 153/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3668 - accuracy: 0.8678 - precision: 0.4752 - recall: 0.0794\n",
      "Epoch 154/250\n",
      "185/185 [==============================] - 0s 838us/step - loss: 0.3525 - accuracy: 0.8728 - precision: 0.6385 - recall: 0.0687\n",
      "Epoch 155/250\n",
      "185/185 [==============================] - 0s 903us/step - loss: 0.3634 - accuracy: 0.8688 - precision: 0.4973 - recall: 0.0761\n",
      "Epoch 156/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3606 - accuracy: 0.8711 - precision: 0.5633 - recall: 0.0736\n",
      "Epoch 157/250\n",
      "185/185 [==============================] - 0s 879us/step - loss: 0.3596 - accuracy: 0.8721 - precision: 0.6090 - recall: 0.0670\n",
      "Epoch 158/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.3655 - accuracy: 0.8697 - precision: 0.5178 - recall: 0.0844\n",
      "Epoch 159/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.3553 - accuracy: 0.8720 - precision: 0.5959 - recall: 0.0720\n",
      "Epoch 160/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.3502 - accuracy: 0.8731 - precision: 0.6512 - recall: 0.0695\n",
      "Epoch 161/250\n",
      "185/185 [==============================] - 0s 855us/step - loss: 0.3536 - accuracy: 0.8708 - precision: 0.5563 - recall: 0.0695\n",
      "Epoch 162/250\n",
      "185/185 [==============================] - 0s 821us/step - loss: 0.3563 - accuracy: 0.8706 - precision: 0.5426 - recall: 0.0844\n",
      "Epoch 163/250\n",
      "185/185 [==============================] - 0s 823us/step - loss: 0.3478 - accuracy: 0.8748 - precision: 0.7077 - recall: 0.0761\n",
      "Epoch 164/250\n",
      "185/185 [==============================] - 0s 835us/step - loss: 0.3503 - accuracy: 0.8740 - precision: 0.6556 - recall: 0.0819\n",
      "Epoch 165/250\n",
      "185/185 [==============================] - 0s 837us/step - loss: 0.3525 - accuracy: 0.8727 - precision: 0.6061 - recall: 0.0827\n",
      "Epoch 166/250\n",
      "185/185 [==============================] - 0s 826us/step - loss: 0.3497 - accuracy: 0.8726 - precision: 0.6118 - recall: 0.0769\n",
      "Epoch 167/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.3540 - accuracy: 0.8717 - precision: 0.5783 - recall: 0.0794\n",
      "Epoch 168/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.3474 - accuracy: 0.8730 - precision: 0.6338 - recall: 0.0744\n",
      "Epoch 169/250\n",
      "185/185 [==============================] - 0s 897us/step - loss: 0.3549 - accuracy: 0.8740 - precision: 0.6374 - recall: 0.0902\n",
      "Epoch 170/250\n",
      "185/185 [==============================] - 0s 912us/step - loss: 0.3522 - accuracy: 0.8721 - precision: 0.5868 - recall: 0.0811\n",
      "Epoch 171/250\n",
      "185/185 [==============================] - 0s 912us/step - loss: 0.3456 - accuracy: 0.8743 - precision: 0.6453 - recall: 0.0918\n",
      "Epoch 172/250\n",
      "185/185 [==============================] - 0s 886us/step - loss: 0.3429 - accuracy: 0.8726 - precision: 0.6133 - recall: 0.0761\n",
      "Epoch 173/250\n",
      "185/185 [==============================] - 0s 900us/step - loss: 0.3505 - accuracy: 0.8725 - precision: 0.6000 - recall: 0.0819\n",
      "Epoch 174/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 810us/step - loss: 0.3484 - accuracy: 0.8736 - precision: 0.6257 - recall: 0.0885\n",
      "Epoch 175/250\n",
      "185/185 [==============================] - 0s 861us/step - loss: 0.3416 - accuracy: 0.8744 - precision: 0.6645 - recall: 0.0852\n",
      "Epoch 176/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3497 - accuracy: 0.8728 - precision: 0.6125 - recall: 0.0811\n",
      "Epoch 177/250\n",
      "185/185 [==============================] - 0s 924us/step - loss: 0.3557 - accuracy: 0.8731 - precision: 0.6010 - recall: 0.0959\n",
      "Epoch 178/250\n",
      "185/185 [==============================] - 0s 963us/step - loss: 0.3425 - accuracy: 0.8749 - precision: 0.6897 - recall: 0.0827\n",
      "Epoch 179/250\n",
      "185/185 [==============================] - 0s 960us/step - loss: 0.3469 - accuracy: 0.8729 - precision: 0.5989 - recall: 0.0926\n",
      "Epoch 180/250\n",
      "185/185 [==============================] - 0s 964us/step - loss: 0.3443 - accuracy: 0.8723 - precision: 0.5847 - recall: 0.0885\n",
      "Epoch 181/250\n",
      "185/185 [==============================] - 0s 979us/step - loss: 0.3539 - accuracy: 0.8721 - precision: 0.5662 - recall: 0.1026\n",
      "Epoch 182/250\n",
      "185/185 [==============================] - 0s 959us/step - loss: 0.3454 - accuracy: 0.8727 - precision: 0.5956 - recall: 0.0902\n",
      "Epoch 183/250\n",
      "185/185 [==============================] - 0s 898us/step - loss: 0.3432 - accuracy: 0.8759 - precision: 0.6739 - recall: 0.1026\n",
      "Epoch 184/250\n",
      "185/185 [==============================] - 0s 889us/step - loss: 0.3389 - accuracy: 0.8756 - precision: 0.6782 - recall: 0.0976\n",
      "Epoch 185/250\n",
      "185/185 [==============================] - 0s 889us/step - loss: 0.3404 - accuracy: 0.8757 - precision: 0.6957 - recall: 0.0926\n",
      "Epoch 186/250\n",
      "185/185 [==============================] - 0s 916us/step - loss: 0.3438 - accuracy: 0.8744 - precision: 0.6335 - recall: 0.1001\n",
      "Epoch 187/250\n",
      "185/185 [==============================] - 0s 823us/step - loss: 0.3453 - accuracy: 0.8733 - precision: 0.6099 - recall: 0.0918\n",
      "Epoch 188/250\n",
      "185/185 [==============================] - 0s 819us/step - loss: 0.3408 - accuracy: 0.8749 - precision: 0.6571 - recall: 0.0951\n",
      "Epoch 189/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.3409 - accuracy: 0.8726 - precision: 0.5842 - recall: 0.0976\n",
      "Epoch 190/250\n",
      "185/185 [==============================] - 0s 825us/step - loss: 0.3345 - accuracy: 0.8766 - precision: 0.7290 - recall: 0.0935\n",
      "Epoch 191/250\n",
      "185/185 [==============================] - 0s 831us/step - loss: 0.3391 - accuracy: 0.8751 - precision: 0.6351 - recall: 0.1108\n",
      "Epoch 192/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3348 - accuracy: 0.8766 - precision: 0.6983 - recall: 0.1034\n",
      "Epoch 193/250\n",
      "185/185 [==============================] - 0s 830us/step - loss: 0.3376 - accuracy: 0.8762 - precision: 0.6936 - recall: 0.0993\n",
      "Epoch 194/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.3398 - accuracy: 0.8764 - precision: 0.6734 - recall: 0.1108\n",
      "Epoch 195/250\n",
      "185/185 [==============================] - 0s 891us/step - loss: 0.3374 - accuracy: 0.8766 - precision: 0.6919 - recall: 0.1059\n",
      "Epoch 196/250\n",
      "185/185 [==============================] - 0s 864us/step - loss: 0.3315 - accuracy: 0.8770 - precision: 0.7219 - recall: 0.1009\n",
      "Epoch 197/250\n",
      "185/185 [==============================] - 0s 874us/step - loss: 0.3323 - accuracy: 0.8776 - precision: 0.7247 - recall: 0.1067\n",
      "Epoch 198/250\n",
      "185/185 [==============================] - 0s 835us/step - loss: 0.3390 - accuracy: 0.8744 - precision: 0.6186 - recall: 0.1100\n",
      "Epoch 199/250\n",
      "185/185 [==============================] - 0s 828us/step - loss: 0.3342 - accuracy: 0.8760 - precision: 0.6796 - recall: 0.1017\n",
      "Epoch 200/250\n",
      "185/185 [==============================] - 0s 837us/step - loss: 0.3307 - accuracy: 0.8781 - precision: 0.7348 - recall: 0.1100\n",
      "Epoch 201/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3294 - accuracy: 0.8791 - precision: 0.7448 - recall: 0.1183\n",
      "Epoch 202/250\n",
      "185/185 [==============================] - 0s 841us/step - loss: 0.3335 - accuracy: 0.8768 - precision: 0.6746 - recall: 0.1166\n",
      "Epoch 203/250\n",
      "185/185 [==============================] - 0s 805us/step - loss: 0.3382 - accuracy: 0.8756 - precision: 0.6476 - recall: 0.1125\n",
      "Epoch 204/250\n",
      "185/185 [==============================] - 0s 849us/step - loss: 0.3296 - accuracy: 0.8787 - precision: 0.7419 - recall: 0.1141\n",
      "Epoch 205/250\n",
      "185/185 [==============================] - 0s 845us/step - loss: 0.3291 - accuracy: 0.8785 - precision: 0.7391 - recall: 0.1125\n",
      "Epoch 206/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.3303 - accuracy: 0.8770 - precision: 0.6923 - recall: 0.1117\n",
      "Epoch 207/250\n",
      "185/185 [==============================] - 0s 862us/step - loss: 0.3278 - accuracy: 0.8807 - precision: 0.7633 - recall: 0.1307\n",
      "Epoch 208/250\n",
      "185/185 [==============================] - 0s 854us/step - loss: 0.3286 - accuracy: 0.8762 - precision: 0.6618 - recall: 0.1133\n",
      "Epoch 209/250\n",
      "185/185 [==============================] - 0s 808us/step - loss: 0.3296 - accuracy: 0.8773 - precision: 0.6954 - recall: 0.1133\n",
      "Epoch 210/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.3308 - accuracy: 0.8778 - precision: 0.6916 - recall: 0.1224\n",
      "Epoch 211/250\n",
      "185/185 [==============================] - 0s 891us/step - loss: 0.3267 - accuracy: 0.8799 - precision: 0.7853 - recall: 0.1150\n",
      "Epoch 212/250\n",
      "185/185 [==============================] - 0s 885us/step - loss: 0.3288 - accuracy: 0.8781 - precision: 0.7094 - recall: 0.1191\n",
      "Epoch 213/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.3266 - accuracy: 0.8791 - precision: 0.7304 - recall: 0.1232\n",
      "Epoch 214/250\n",
      "185/185 [==============================] - 0s 813us/step - loss: 0.3200 - accuracy: 0.8820 - precision: 0.8071 - recall: 0.1315\n",
      "Epoch 215/250\n",
      "185/185 [==============================] - 0s 852us/step - loss: 0.3243 - accuracy: 0.8791 - precision: 0.7176 - recall: 0.1282\n",
      "Epoch 216/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3258 - accuracy: 0.8781 - precision: 0.6923 - recall: 0.1266\n",
      "Epoch 217/250\n",
      "185/185 [==============================] - 0s 886us/step - loss: 0.3268 - accuracy: 0.8775 - precision: 0.6837 - recall: 0.1216\n",
      "Epoch 218/250\n",
      "185/185 [==============================] - 0s 873us/step - loss: 0.3267 - accuracy: 0.8802 - precision: 0.7500 - recall: 0.1290\n",
      "Epoch 219/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.3249 - accuracy: 0.8791 - precision: 0.6850 - recall: 0.1439\n",
      "Epoch 220/250\n",
      "185/185 [==============================] - 0s 816us/step - loss: 0.3190 - accuracy: 0.8791 - precision: 0.7176 - recall: 0.1282\n",
      "Epoch 221/250\n",
      "185/185 [==============================] - 0s 859us/step - loss: 0.3240 - accuracy: 0.8795 - precision: 0.7402 - recall: 0.1249\n",
      "Epoch 222/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.3342 - accuracy: 0.8754 - precision: 0.6181 - recall: 0.1299\n",
      "Epoch 223/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.3216 - accuracy: 0.8812 - precision: 0.7756 - recall: 0.1315\n",
      "Epoch 224/250\n",
      "185/185 [==============================] - 0s 815us/step - loss: 0.3169 - accuracy: 0.8817 - precision: 0.7810 - recall: 0.1356\n",
      "Epoch 225/250\n",
      "185/185 [==============================] - 0s 909us/step - loss: 0.3221 - accuracy: 0.8815 - precision: 0.7710 - recall: 0.1365\n",
      "Epoch 226/250\n",
      "185/185 [==============================] - 0s 880us/step - loss: 0.3198 - accuracy: 0.8820 - precision: 0.7574 - recall: 0.1472\n",
      "Epoch 227/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.3182 - accuracy: 0.8811 - precision: 0.7745 - recall: 0.1307\n",
      "Epoch 228/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.3226 - accuracy: 0.8804 - precision: 0.7054 - recall: 0.1505\n",
      "Epoch 229/250\n",
      "185/185 [==============================] - 0s 844us/step - loss: 0.3152 - accuracy: 0.8807 - precision: 0.7583 - recall: 0.1323\n",
      "Epoch 230/250\n",
      "185/185 [==============================] - 0s 848us/step - loss: 0.3135 - accuracy: 0.8833 - precision: 0.8037 - recall: 0.1456\n",
      "Epoch 231/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 886us/step - loss: 0.3175 - accuracy: 0.8805 - precision: 0.7277 - recall: 0.1414\n",
      "Epoch 232/250\n",
      "185/185 [==============================] - 0s 867us/step - loss: 0.3107 - accuracy: 0.8849 - precision: 0.8128 - recall: 0.1580\n",
      "Epoch 233/250\n",
      "185/185 [==============================] - 0s 856us/step - loss: 0.3216 - accuracy: 0.8808 - precision: 0.7331 - recall: 0.1431\n",
      "Epoch 234/250\n",
      "185/185 [==============================] - 0s 865us/step - loss: 0.3197 - accuracy: 0.8814 - precision: 0.7237 - recall: 0.1538\n",
      "Epoch 235/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3138 - accuracy: 0.8820 - precision: 0.7597 - recall: 0.1464\n",
      "Epoch 236/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3157 - accuracy: 0.8819 - precision: 0.7290 - recall: 0.1580\n",
      "Epoch 237/250\n",
      "185/185 [==============================] - 0s 833us/step - loss: 0.3182 - accuracy: 0.8818 - precision: 0.7352 - recall: 0.1538\n",
      "Epoch 238/250\n",
      "185/185 [==============================] - 0s 842us/step - loss: 0.3139 - accuracy: 0.8801 - precision: 0.6988 - recall: 0.1497\n",
      "Epoch 239/250\n",
      "185/185 [==============================] - 0s 809us/step - loss: 0.3106 - accuracy: 0.8834 - precision: 0.7769 - recall: 0.1555\n",
      "Epoch 240/250\n",
      "185/185 [==============================] - 0s 840us/step - loss: 0.3079 - accuracy: 0.8823 - precision: 0.7375 - recall: 0.1580\n",
      "Epoch 241/250\n",
      "185/185 [==============================] - 0s 822us/step - loss: 0.3146 - accuracy: 0.8828 - precision: 0.7645 - recall: 0.1530\n",
      "Epoch 242/250\n",
      "185/185 [==============================] - 0s 919us/step - loss: 0.3075 - accuracy: 0.8839 - precision: 0.7851 - recall: 0.1572\n",
      "Epoch 243/250\n",
      "185/185 [==============================] - 0s 906us/step - loss: 0.3122 - accuracy: 0.8815 - precision: 0.7117 - recall: 0.1613\n",
      "Epoch 244/250\n",
      "185/185 [==============================] - 0s 895us/step - loss: 0.3083 - accuracy: 0.8839 - precision: 0.7760 - recall: 0.1605\n",
      "Epoch 245/250\n",
      "185/185 [==============================] - 0s 892us/step - loss: 0.3112 - accuracy: 0.8824 - precision: 0.7348 - recall: 0.1605\n",
      "Epoch 246/250\n",
      "185/185 [==============================] - 0s 897us/step - loss: 0.3077 - accuracy: 0.8826 - precision: 0.7316 - recall: 0.1646\n",
      "Epoch 247/250\n",
      "185/185 [==============================] - 0s 908us/step - loss: 0.3103 - accuracy: 0.8842 - precision: 0.7601 - recall: 0.1704\n",
      "Epoch 248/250\n",
      "185/185 [==============================] - 0s 894us/step - loss: 0.3090 - accuracy: 0.8846 - precision: 0.7580 - recall: 0.1762\n",
      "Epoch 249/250\n",
      "185/185 [==============================] - 0s 847us/step - loss: 0.3077 - accuracy: 0.8847 - precision: 0.7684 - recall: 0.1729\n",
      "Epoch 250/250\n",
      "185/185 [==============================] - 0s 857us/step - loss: 0.3127 - accuracy: 0.8828 - precision: 0.7424 - recall: 0.1621\n",
      "289/289 [==============================] - 0s 580us/step - loss: 0.3060 - accuracy: 0.8853 - precision: 0.9081 - recall: 0.1390\n",
      "Accuracy: 88.53\n",
      "precision: 90.81\n",
      "recall rate: 13.90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "X = np.array(CT_Data)\n",
    "standardScalar = StandardScaler()\n",
    "standardScalar.fit(X)\n",
    "standardScalar.transform(X)\n",
    "X = X.T\n",
    "X = X.astype(float)\n",
    "y = np.array(Outcome_Data[21])\n",
    "y = y.astype(int)\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=11, use_bias=True))\n",
    "model.add(Dense(64, activation='relu',use_bias=True))\n",
    "model.add(Dense(128, activation='relu',use_bias=True))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy','Precision','Recall'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=250, batch_size=50)\n",
    "# evaluate the keras model\n",
    "_, accuracy,precision,recall = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('precision: %.2f' % (precision*100))\n",
    "print('recall rate: %.2f' % (recall*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(9223, 1)\n",
      "8165\n",
      "1058\n",
      "168\n",
      "validation accuracy is: 0.885286783042394. Successfully detected cancer: 168\n",
      "precision score is: 90.8108%\n",
      "recall_score is: 13.8958%\n",
      "f1_score: 24.1033%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_y = model.predict(X)\n",
    "print(X.shape)\n",
    "print(test_y.shape)\n",
    "test_y = test_y > 0.5\n",
    "right_count = 0\n",
    "wrong_count = 0\n",
    "cancer_dectected = 0\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == y[i]:\n",
    "        right_count = right_count + 1\n",
    "        if test_y[i] == True:\n",
    "            cancer_dectected = cancer_dectected + 1\n",
    "    else:\n",
    "        wrong_count = wrong_count + 1\n",
    "print(right_count)\n",
    "print(wrong_count)\n",
    "print(cancer_dectected)\n",
    "print(\"validation accuracy is: \"+str(right_count / (right_count + wrong_count)) + \". Successfully detected cancer: \"+str(cancer_dectected))\n",
    "print(\"precision score is: {0:.4%}\".format(precision_score(y, test_y)))\n",
    "print(\"recall_score is: {0:.4%}\".format(recall_score(y, test_y)))\n",
    "print(\"f1_score: {0:.4%}\".format(f1_score(y, test_y)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
