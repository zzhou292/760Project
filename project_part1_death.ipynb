{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "from pandas import *\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "from helper760 import read_inputs\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import tensorflow as tf\n",
    "re_train_1 = False\n",
    "re_train_2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Use both clinic and ct data to predict death day\n",
    "Note that we have only around 549 real samples with known death day for us to train the model\n",
    "\n",
    "Currently, we use these 549 samples as training set, and the rest will be the prediction set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data for step 1\n",
    "Clininc_Data,Outcome_Data,CT_Data = read_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out who has known death day\n",
    "n_sample = len(Outcome_Data[0])\n",
    "fill_train_idx = []\n",
    "fill_test_idx = []\n",
    "\n",
    "for i in range(n_sample):\n",
    "    if Outcome_Data[0][i]!=0:\n",
    "        fill_train_idx.append(i)\n",
    "    else:\n",
    "        fill_test_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(9223, 10)\n",
      "(9223, 21)\n",
      "(549, 21)\n",
      "(8674, 21)\n",
      "(549, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare the data for training\n",
    "# in this case we use both the clinic data and ct data\n",
    "X1 = np.array(CT_Data)\n",
    "X1 = X1.T\n",
    "X1 = X1.astype(float)\n",
    "print(X1.shape)\n",
    "\n",
    "X2 = np.array(Clininc_Data)\n",
    "X2 = X2.T\n",
    "X2 = X2[:,4:14]\n",
    "X2 = X2.astype(float)\n",
    "print(X2.shape)\n",
    "\n",
    "X = np.hstack((X1,X2))\n",
    "print(X.shape)\n",
    "\n",
    "X_fill_train = X[fill_train_idx,:]\n",
    "print(X_fill_train.shape)\n",
    "\n",
    "X_fill_test = X[fill_test_idx,:]\n",
    "print(X_fill_test.shape)\n",
    "\n",
    "y_fill_train = np.array(Outcome_Data[0])\n",
    "y_fill_train = y_fill_train.astype(int)\n",
    "y_fill_train = np.asmatrix(y_fill_train)\n",
    "y_fill_train = y_fill_train.T\n",
    "y_fill_train = y_fill_train[fill_train_idx,:]\n",
    "print(y_fill_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model use the 549 samples, with clinic data + ct data\n",
    "if re_train_1 == True:\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=21, use_bias=True))\n",
    "    model.add(Dense(64, activation='relu',use_bias=True))\n",
    "    model.add(Dense(128, activation='relu',use_bias=True))\n",
    "    model.add(Dense(256, activation='relu',use_bias=True))\n",
    "    model.add(Dense(512, activation='relu',use_bias=True))\n",
    "    model.add(Dense(1))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "    # compile the keras model\n",
    "    model.compile(loss='MeanSquaredError', optimizer=opt, metrics=['MeanSquaredError'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_fill_train, y_fill_train, epochs=5000, batch_size=20,verbose=1)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"keras_model_step_1\", custom_objects=None, compile=True, options=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average death day error across all 549 traing sample: 9.732171554600171\n"
     ]
    }
   ],
   "source": [
    "# let's see how the model fits the original training data\n",
    "y_fill_train_predict = model.predict(X_fill_train)\n",
    "err_sum = 0\n",
    "for i in range((y_fill_train_predict.shape)[0]):\n",
    "    err_sum = err_sum + (abs(y_fill_train_predict[i,0]-y_fill_train[i,0]))\n",
    "print(\"average death day error across all 549 traing sample: \"+str(err_sum/(y_fill_train_predict.shape)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 573us/step - loss: 171.4919 - mean_squared_error: 171.4919\n",
      "[171.49191284179688, 171.49191284179688]\n"
     ]
    }
   ],
   "source": [
    "# save/evaluate the model used for step 1\n",
    "from datetime import datetime\n",
    "if re_train_1 == True:\n",
    "    model.save(\"keras_model_step_1\")\n",
    "    \n",
    "score = model.evaluate(X_fill_train, y_fill_train, verbose = 1) \n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 25)\n",
      "(9223, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328402/2655353469.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_outcome = np.array(Outcome_Data)\n"
     ]
    }
   ],
   "source": [
    "# fill in the missing death day data using both clinic data and ct data\n",
    "y_fill_test_predict = model.predict(X_fill_test)\n",
    "for i in range(len(fill_test_idx)):\n",
    "    if y_fill_test_predict[i] < 0:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = 0\n",
    "    else:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = y_fill_test_predict[i]\n",
    "\n",
    "np_outcome = np.array(Outcome_Data)\n",
    "np_ctdata = np.array(CT_Data)\n",
    "np_outcome = np_outcome.T\n",
    "np_ctdata = np_ctdata.T\n",
    "print(np_outcome.shape)\n",
    "print(np_ctdata.shape)\n",
    "\n",
    "out_csv = np.column_stack((np_outcome,np_ctdata))\n",
    "out_csv = out_csv.astype(float)\n",
    "\n",
    "np.savetxt(\"test_death_day_1.csv\", out_csv, fmt='%f',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Use only ct data to predict death day\n",
    "Note that we have only around 549 real samples with known death day for us to train the model\n",
    "\n",
    "In this case, we use only CT data to predict death, we use the 549 samples with death day as training set, and predict the samples with missing death day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reread the data to clear variables\n",
    "Clininc_Data,Outcome_Data,CT_Data = read_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 11)\n",
      "(549, 11)\n",
      "(8674, 11)\n",
      "(549, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare data for training, this case we use ct data only\n",
    "X1 = np.array(CT_Data)\n",
    "X1 = X1.T\n",
    "X1 = X1.astype(float)\n",
    "print(X1.shape)\n",
    "\n",
    "X_fill_train_2 = X1[fill_train_idx,:]\n",
    "print(X_fill_train_2.shape)\n",
    "\n",
    "X_fill_test_2 = X1[fill_test_idx,:]\n",
    "print(X_fill_test_2.shape)\n",
    "\n",
    "y_fill_train_2 = np.array(Outcome_Data[0])\n",
    "y_fill_train_2 = y_fill_train_2.astype(int)\n",
    "y_fill_train_2 = np.asmatrix(y_fill_train_2)\n",
    "y_fill_train_2 = y_fill_train_2.T\n",
    "y_fill_train_2 = y_fill_train_2[fill_train_idx,:]\n",
    "print(y_fill_train_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model used for step 2\n",
    "if re_train_2 == True:\n",
    "    # define the keras model\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(32, input_dim=11, use_bias=True))\n",
    "    model_2.add(Dense(64, activation='relu',use_bias=True))\n",
    "    model_2.add(Dense(128, activation='relu',use_bias=True))\n",
    "    model_2.add(Dense(256, activation='relu',use_bias=True))\n",
    "    model_2.add(Dense(512, activation='relu',use_bias=True))\n",
    "    model_2.add(Dense(1))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "    # compile the keras model\n",
    "    model_2.compile(loss='MeanSquaredError', optimizer=opt, metrics=['MeanSquaredError'])\n",
    "    # fit the keras model on the dataset\n",
    "    model_2.fit(X_fill_train_2, y_fill_train_2, epochs=5000, batch_size=20,verbose=1)\n",
    "else:\n",
    "    model_2 = tf.keras.models.load_model(\"keras_model_step_2\", custom_objects=None, compile=True, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 570us/step - loss: 3.3247 - mean_squared_error: 3.3247\n",
      "[3.324714183807373, 3.324714183807373]\n",
      "average death day error across all 549 traing sample: 1.1271004911328926\n"
     ]
    }
   ],
   "source": [
    "# save/evaluate the model\n",
    "from datetime import datetime\n",
    "if re_train_2 == True:\n",
    "    model_2.save(\"keras_model_step_2\")\n",
    "score_2 = model_2.evaluate(X_fill_train_2, y_fill_train_2, verbose = 1) \n",
    "print(score_2)\n",
    "\n",
    "# let's see how the model fits the original training set\n",
    "err_sum = 0\n",
    "y_fill_train_predict_2 = model_2.predict(X_fill_train_2)\n",
    "for i in range((y_fill_train_predict_2.shape)[0]):\n",
    "    err_sum = err_sum + (abs(y_fill_train_predict_2[i,0]-y_fill_train_2[i,0]))\n",
    "print(\"average death day error across all 549 traing sample: \"+str(err_sum/(y_fill_train_predict_2.shape)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9223, 25)\n",
      "(9223, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328402/3395699980.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_outcome = np.array(Outcome_Data)\n"
     ]
    }
   ],
   "source": [
    "# predict and fill the missing death day field\n",
    "y_fill_test_predict_2 = model_2.predict(X_fill_test_2)\n",
    "\n",
    "for i in range(len(fill_test_idx)):\n",
    "    if y_fill_test_predict_2[i] < 0:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = 0\n",
    "    else:\n",
    "        Outcome_Data[0][fill_test_idx[i]] = y_fill_test_predict_2[i]\n",
    "\n",
    "np_outcome = np.array(Outcome_Data)\n",
    "np_ctdata = np.array(CT_Data)\n",
    "np_outcome = np_outcome.T\n",
    "np_ctdata = np_ctdata.T\n",
    "print(np_outcome.shape)\n",
    "print(np_ctdata.shape)\n",
    "\n",
    "out_csv = np.column_stack((np_outcome,np_ctdata))\n",
    "out_csv = out_csv.astype(float)\n",
    "\n",
    "np.savetxt(\"test_death_day_2.csv\", out_csv, fmt='%f',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
